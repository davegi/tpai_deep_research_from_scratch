{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Educational Research Notebook\n",
    "\n",
    "This notebook demonstrates a complete multi-agent research system that combines:\n",
    "\n",
    "- **Full Research Workflow** (from `5_full_agent.ipynb`): Complete end-to-end research process\n",
    "- **MCP Integration** (from `3_research_agent_mcp.ipynb`): Model Context Protocol for tool access\n",
    "- **Test-Synchronized Examples** (from `0_consolidated_research_agent.ipynb`): Deterministic demonstrations\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "\n",
    "1. **System Architecture**: How multi-agent research systems are structured\n",
    "2. **MCP Integration**: How to use Model Context Protocol for tool access\n",
    "3. **LLM Impact**: How different prompts and LLM settings affect research quality\n",
    "4. **Workflow Orchestration**: How LangGraph coordinates complex research workflows\n",
    "5. **Test-Driven Development**: How to build reliable, testable AI systems\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic understanding of Python and async programming\n",
    "- Familiarity with Jupyter notebooks\n",
    "- Understanding of LLMs and their capabilities\n",
    "- Basic knowledge of agent-based systems\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "This notebook is organized into distinct sections, each building upon the previous:\n",
    "\n",
    "1. **Bootstrap & Setup**: Environment configuration and initialization\n",
    "2. **Core Components**: Understanding the building blocks\n",
    "3. **MCP Integration**: Tool access and async operations\n",
    "4. **Research Workflow**: Complete end-to-end process\n",
    "5. **LLM Impact Analysis**: Understanding prompt and model effects\n",
    "6. **Test Synchronization**: Ensuring reliability and reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Bootstrap & Setup\n",
    "\n",
    "The first step in any robust AI system is proper initialization and configuration. This section demonstrates:\n",
    "\n",
    "- **Environment Setup**: Loading configuration and setting up logging\n",
    "- **Path Management**: Ensuring proper imports and module discovery\n",
    "- **Bootstrap Process**: Initializing the research framework\n",
    "- **Console Configuration**: Setting up rich output for educational purposes\n",
    "\n",
    "### Why Bootstrap Matters\n",
    "\n",
    "Bootstrap ensures that:\n",
    "1. Environment variables are loaded correctly\n",
    "2. Logging is configured for debugging and monitoring\n",
    "3. Console output is formatted for readability\n",
    "4. All dependencies are properly initialized\n",
    "5. Error handling is set up with rich tracebacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Anchors and Test Crossâ€‘links\n",
    "\n",
    "- [ ] Section 2: Core Components â€” see `tests/test_research_agent.py`\n",
    "- [ ] Section 3: MCP Integration â€” see `tests/test_renderer_rich.py`\n",
    "- [ ] Section 4: Research Workflow â€” see `tests/test_end_to_end_flow.py`\n",
    "- [ ] Section 5: LLM Impact Analysis â€” see `tests/test_llm_mock.py`\n",
    "- [ ] Section 6: Test Synchronization â€” see `tests/test_renderer.py`\n",
    "- [ ] Search Adapters (SerpAPI/Tavily) â€” see `tests/test_serpapi_adapter.py`, `tests/test_tavily_adapter.py`, `tests/test_serpapi_and_tavily_adapters.py`, `tests/test_adapters*.py`\n",
    "- [ ] Supervisor Policy Demo â€” see `tests/test_supervisor_policy.py`, `tests/test_supervisor_policy_deterministic.py`\n",
    "- [ ] Bootstrap & Config Walkthrough â€” see `tests/test_bootstrap.py`, `tests/test_bootstrap_wiring.py`, `tests/test_config.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook helper: ensure bootstrap runs early and use centralized helpers\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from rich.console import Console\n",
    "\n",
    "# Ensure local `src` is on sys.path so imports like `research_agent_framework` work\n",
    "repo_cwd = Path.cwd().resolve()\n",
    "found_src = None\n",
    "for candidate in [repo_cwd] + list(repo_cwd.parents):\n",
    "    if (candidate / \"src\" / \"research_agent_framework\").exists():\n",
    "        found_src = (candidate / \"src\").resolve()\n",
    "        break\n",
    "if found_src is None:\n",
    "    candidate = (repo_cwd / \"..\" / \"src\").resolve()\n",
    "    if (candidate / \"research_agent_framework\").exists():\n",
    "        found_src = candidate\n",
    "if found_src is not None and str(found_src) not in sys.path:\n",
    "    sys.path.insert(0, str(found_src))\n",
    "\n",
    "# Import project bootstrap and helpers\n",
    "from research_agent_framework.bootstrap import bootstrap\n",
    "from research_agent_framework.config import get_settings, get_console, get_logger\n",
    "\n",
    "# Initialize environment, console, and logging (idempotent)\n",
    "bootstrap()\n",
    "\n",
    "# Obtain shared handles via helpers\n",
    "settings = get_settings()\n",
    "console = get_console()\n",
    "logger = get_logger()\n",
    "\n",
    "def nb_console():\n",
    "    \"\"\"\n",
    "    Return the project's shared `Console` instance via `get_console()`.\n",
    "    This ensures consistent rich output formatting throughout the notebook.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return get_console()\n",
    "    except Exception:\n",
    "        return Console()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Process Demonstration\n",
    "\n",
    "Now let's run the bootstrap process and see what it initializes. This demonstrates how a production AI system should start up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ğŸ”„ Running bootstrap process<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ğŸ”„ Running bootstrap process\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Bootstrap Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">âœ… Bootstrap Complete</span>                             â”‚\n",
       "â”‚                                                   â”‚\n",
       "â”‚ The research framework has been initialized with: â”‚\n",
       "â”‚ â€¢ Environment variables loaded                    â”‚\n",
       "â”‚ â€¢ Logging configured (console sink)               â”‚\n",
       "â”‚ â€¢ Console formatting enabled                      â”‚\n",
       "â”‚ â€¢ Error handling set up                           â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Bootstrap Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ \u001b[1;32mâœ… Bootstrap Complete\u001b[0m                             â”‚\n",
       "â”‚                                                   â”‚\n",
       "â”‚ The research framework has been initialized with: â”‚\n",
       "â”‚ â€¢ Environment variables loaded                    â”‚\n",
       "â”‚ â€¢ Logging configured (console sink)               â”‚\n",
       "â”‚ â€¢ Console formatting enabled                      â”‚\n",
       "â”‚ â€¢ Error handling set up                           â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Framework Configuration                               </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Component            </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Status          </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Details                                  </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Environment          </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Loaded       </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Variables from .env file (if present)    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Logging              </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Configured   </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Loguru wired to Rich Console             </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Console              </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Ready        </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Rich formatting enabled                  </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Error Handling       </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Active       </span>â”‚<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Rich tracebacks installed                </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Framework Configuration                               \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mComponent           \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mStatus         \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mDetails                                 \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mEnvironment         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Loaded      \u001b[0m\u001b[32m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37mVariables from .env file (if present)   \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mLogging             \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Configured  \u001b[0m\u001b[32m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37mLoguru wired to Rich Console            \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mConsole             \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Ready       \u001b[0m\u001b[32m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37mRich formatting enabled                 \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mError Handling      \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Active      \u001b[0m\u001b[32m \u001b[0mâ”‚\u001b[37m \u001b[0m\u001b[37mRich tracebacks installed               \u001b[0m\u001b[37m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bootstrap the research framework\n",
    "# This initializes logging, console, and environment configuration\n",
    "from research_agent_framework.bootstrap import bootstrap\n",
    "from research_agent_framework.config import get_settings, get_console, get_logger\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "\n",
    "# Run bootstrap to configure the environment\n",
    "console.print(\"ğŸ”„ Running bootstrap process...\")\n",
    "bootstrap()\n",
    "\n",
    "# Get the configured settings, console, and logger\n",
    "settings = get_settings()\n",
    "console = settings.console # get_console()\n",
    "logger = settings.logger # get_logger()\n",
    "\n",
    "# Display bootstrap information\n",
    "console.print(Panel(\n",
    "    \"[bold green]âœ… Bootstrap Complete[/bold green]\\n\\n\"\n",
    "    \"The research framework has been initialized with:\\n\"\n",
    "    \"â€¢ Environment variables loaded\\n\"\n",
    "    \"â€¢ Logging configured (console sink)\\n\"\n",
    "    \"â€¢ Console formatting enabled\\n\"\n",
    "    \"â€¢ Error handling set up\",\n",
    "    title=\"Bootstrap Status\",\n",
    "    expand=False\n",
    "))\n",
    "\n",
    "# Show configuration details\n",
    "config_table = Table(title=\"Framework Configuration\", show_header=True, header_style=\"bold magenta\")\n",
    "config_table.add_column(\"Component\", style=\"cyan\", width=20)\n",
    "config_table.add_column(\"Status\", style=\"green\", width=15)\n",
    "config_table.add_column(\"Details\", style=\"white\", width=40)\n",
    "\n",
    "config_table.add_row(\"Environment\", \"âœ… Loaded\", \"Variables from .env file (if present)\")\n",
    "config_table.add_row(\"Logging\", \"âœ… Configured\", \"Loguru wired to Rich Console\")\n",
    "config_table.add_row(\"Console\", \"âœ… Ready\", \"Rich formatting enabled\")\n",
    "config_table.add_row(\"Error Handling\", \"âœ… Active\", \"Rich tracebacks installed\")\n",
    "\n",
    "console.print(config_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration impact on behavior and logging\n",
    "\n",
    "This section explains how changing settings (env vars) impacts runtime:\n",
    "\n",
    "- `model_name` and `model_temperature` influence prompt behavior and deterministic outputs.\n",
    "- `LOGGING__LEVEL` and `LOGGING__FMT` change the logging verbosity and format; the `Settings.logger` property reflects changes when `get_settings(force_reload=True)` is used.\n",
    "- `enable_tracing` toggles optional tracing hooks (visualizations guarded by env).\n",
    "\n",
    "Below is a safe example demonstrating how to reload settings at runtime and observe logger level changes without restarting the notebook.\n",
    "\n",
    "Note: This example mutates process environment variables temporarily and reloads `Settings` with `force_reload=True` to illustrate effects in a deterministic demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reload: logging.level= INFO\n",
      "After reload: logging.level= DEBUG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:39:14</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650937</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO This is an info message <span style=\"font-weight: bold\">(</span>should always show at INFO/DEBUG<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:39:14\u001b[0m.\u001b[1;36m650937\u001b[0m+\u001b[1;36m0000\u001b[0m INFO This is an info message \u001b[1m(\u001b[0mshould always show at INFO/DEBUG\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:39:14.650937+0000 INFO This is an info message (should always show at INFO/DEBUG)\n",
      "2025-09-12T21:39:14.650937+0000 INFO This is an info message (should always show at INFO/DEBUG)\n",
      "2025-09-12T21:39:14.654946+0000 DEBUG This is a debug message (visible only when level=DEBUG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored: logging.level= INFO\n"
     ]
    }
   ],
   "source": [
    "# Demonstration: change logging level via env and reload settings\n",
    "import os\n",
    "from research_agent_framework.config import get_settings, get_logger\n",
    "\n",
    "# Show current logging level\n",
    "settings = get_settings()\n",
    "print(\"Before reload: logging.level=\", settings.logging.level)\n",
    "\n",
    "# Temporarily set environment to DEBUG and reload\n",
    "os.environ[\"LOGGING__LEVEL\"] = \"DEBUG\"\n",
    "settings = get_settings(force_reload=True)\n",
    "print(\"After reload: logging.level=\", settings.logging.level)\n",
    "\n",
    "# Acquire logger and show that level reflects setting\n",
    "logger = get_logger()\n",
    "logger.info(\"This is an info message (should always show at INFO/DEBUG)\")\n",
    "logger.debug(\"This is a debug message (visible only when level=DEBUG)\")\n",
    "\n",
    "# Clean up: restore env and reload to original for deterministic notebook runs\n",
    "os.environ.pop(\"LOGGING__LEVEL\", None)\n",
    "settings = get_settings(force_reload=True)\n",
    "print(\"Restored: logging.level=\", settings.logging.level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture & Technologies (Brief Overview)\n",
    "\n",
    "- **Settings & Bootstrap**: `Settings` (Pydantic) loads env; `bootstrap()` enables rich tracebacks and wires Loguru â†’ Rich `Console`.\n",
    "- **Logging**: `LoggingConfig` fields (`level`, `fmt`, `backend`) drive a lazy `logger` property; helpers delegate to the same instances.\n",
    "- **Agents & Models**: Agents coordinate research steps; Pydantic models (`SerpResult`, `Scope`, etc.) provide typed state.\n",
    "- **Adapters**: Search adapters (SerpAPI/Tavily) expose deterministic stubs with optional live paths.\n",
    "- **Prompts/Renderer**: Jinja templates rendered with rich-markdown output for clarity.\n",
    "- **Tests as Specs**: Notebook sections mirror `tests/` behaviors for deterministic, reproducible demos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Diagram (Components)\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "  subgraph Agents\n",
    "    A[Research Agent]\n",
    "    S[Scoping Agent]\n",
    "    SP[Supervisor]\n",
    "  end\n",
    "\n",
    "  subgraph Framework\n",
    "    CFG[Settings]\n",
    "    LCFG[LoggingConfig]\n",
    "    CON[Console]\n",
    "    LGR[Logger]\n",
    "    PR[Prompt Renderer]\n",
    "    LLM[LLM Client]\n",
    "  end\n",
    "\n",
    "  subgraph Adapters\n",
    "    SERP[SerpAPI Adapter]\n",
    "    TAV[Tavily Adapter]\n",
    "  end\n",
    "\n",
    "  A --> PR\n",
    "  A --> LLM\n",
    "  A --> SERP\n",
    "  A --> TAV\n",
    "  S --> PR\n",
    "  SP --> A\n",
    "  SP --> S\n",
    "\n",
    "  CFG --> CON\n",
    "  CFG --> LCFG\n",
    "  LCFG --> LGR\n",
    "  LGR --> CON\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Diagram (User â†’ Scoping â†’ Research â†’ Synthesis â†’ Report)\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant U as User\n",
    "    participant S as Scoping Agent\n",
    "    participant R as Research Agent\n",
    "    participant L as LLM Client\n",
    "    participant A as Search Adapter\n",
    "    participant P as Prompt Renderer\n",
    "    participant V as Supervisor\n",
    "\n",
    "    U->>S: Provide initial question / constraints\n",
    "    S->>P: Format scoping prompt\n",
    "    P-->>S: Scoped questions / clarifications\n",
    "    S->>U: Ask clarifying question (if needed)\n",
    "    U-->>S: Clarified scope\n",
    "\n",
    "    S->>R: Submit refined scope / research task\n",
    "    R->>P: Render research prompt\n",
    "    P-->>R: Prompt text\n",
    "    R->>L: Query LLM for retrieval & analysis\n",
    "    L-->>R: LLM response (results / suggestions)\n",
    "\n",
    "    R->>A: Run search queries (documents, citations)\n",
    "    A-->>R: Search results (Serp/Tavily)\n",
    "\n",
    "    R->>R: Aggregate findings, synthesize insights\n",
    "    R->>V: Hand-off for supervision / orchestration\n",
    "    V-->>R: Supervisor decisions / reassignments\n",
    "\n",
    "    R->>U: Deliver final report / brief\n",
    "    Note over U,R: Report includes provenance and evidence links\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model Diagram (Key models & relationships)\n",
    "\n",
    "```mermaid\n",
    "classDiagram\n",
    "    direction LR\n",
    "    class SerpResult {\n",
    "        string id\n",
    "        string title\n",
    "        string snippet\n",
    "        string url\n",
    "        list citations\n",
    "        +from_raw(dict) SerpResult\n",
    "    }\n",
    "\n",
    "    class Scope {\n",
    "        string id\n",
    "        string question\n",
    "        list constraints\n",
    "        list clarifications\n",
    "    }\n",
    "\n",
    "    class ResearchTask {\n",
    "        string id\n",
    "        Scope scope\n",
    "        list steps\n",
    "        status\n",
    "    }\n",
    "\n",
    "    class EvalResult {\n",
    "        string task_id\n",
    "        bool success\n",
    "        float score\n",
    "        string feedback\n",
    "        dict details\n",
    "    }\n",
    "\n",
    "    class AgentContext {\n",
    "        settings\n",
    "        console\n",
    "        logger\n",
    "        llm_client\n",
    "        search_adapter\n",
    "    }\n",
    "\n",
    "    SerpResult --|> ResearchTask : evidence\n",
    "    Scope \"1\" o-- \"0..*\" ResearchTask : generates\n",
    "    ResearchTask \"1\" o-- \"0..*\" EvalResult : evaluated_by\n",
    "    AgentContext \"1\" -- \"*\" ResearchTask : used_by\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why this setup (results of the design)\n",
    "\n",
    "- **Env overrides work**: `LOGGING__LEVEL`, `LOGGING__FMT`, `LOGGING__BACKEND` populate real fields; the `logger` property reflects them at access time.\n",
    "- **Single ownership via properties**: `settings.console` and `settings.logger` are the shared instances used everywhere.\n",
    "- **Helpers remain simple**: `get_console()` / `get_logger()` just delegate to those shared instances when you prefer function calls.\n",
    "- **Robust bootstrap**: `bootstrap()` installs rich tracebacks, ensures a Console, and wires Loguru â†’ Console idempotently.\n",
    "- **Notebook consistency**: Cells use property access (e.g., `settings.console`) for clarity; helpers are equivalent if preferred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env vars: required and optional (4.1)\n",
    "\n",
    "Key environment variables used by the framework (recommended defaults shown):\n",
    "\n",
    "| Variable | Required? | Default | Description |\n",
    "|---|---:|---|---|\n",
    "| `SERPAPI_API_KEY` | Optional | â€” | API key for SerpAPI; if missing, notebook defaults to `Mock` adapter |\n",
    "| `TAVILY_API_KEY` | Optional | â€” | API key for Tavily adapter; if missing, notebook defaults to `Mock` adapter |\n",
    "| `LOGGING__LEVEL` | Optional | `INFO` | Logging verbosity |\n",
    "| `LOGGING__FMT` | Optional | project default | Logging format string |\n",
    "| `MODEL_NAME` | Optional | `mock-model` | LLM model to use when not mocking |\n",
    "| `MODEL_TEMPERATURE` | Optional | `0.0` | Controls LLM sampling |\n",
    "| `ENABLE_TRACING` | Optional | `False` | Enable tracing hooks |\n",
    "\n",
    "This section lists recommended env vars, safe defaults, and guidance on toggling live providers vs mocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME = mock-model\n",
      "MODEL_TEMPERATURE = 0.0\n",
      "LOGGING__LEVEL = INFO\n",
      "ENABLE_TRACING = False\n",
      "SERPAPI_API_KEY present: False\n",
      "TAVILY_API_KEY present: True\n"
     ]
    }
   ],
   "source": [
    "# Safe demo: display resolved settings and show defaults\n",
    "from research_agent_framework.config import get_settings\n",
    "\n",
    "s = get_settings(force_reload=True)\n",
    "print('MODEL_NAME =', s.model_name)\n",
    "print('MODEL_TEMPERATURE =', s.model_temperature)\n",
    "print('LOGGING__LEVEL =', s.logging.level)\n",
    "print('ENABLE_TRACING =', s.enable_tracing)\n",
    "\n",
    "# Display whether external adapter keys are present\n",
    "import os\n",
    "print('SERPAPI_API_KEY present:', bool(os.environ.get('SERPAPI_API_KEY')))\n",
    "print('TAVILY_API_KEY present:', bool(os.environ.get('TAVILY_API_KEY')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safe defaults and fallback behavior (4.2)\n",
    "\n",
    "This cell demonstrates how the notebook and framework behave when external API keys are not provided. By default the notebook uses deterministic `Mock` adapters and `MockLLM` to keep examples reproducible and low-cost.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- If `SERPAPI_API_KEY` or `TAVILY_API_KEY` are missing, the framework falls back to the `Mock` search adapter.\n",
    "- If `MODEL_NAME` is set to a real provider name, `llm_factory` will create a live client â€” otherwise the `MockLLM` is used.\n",
    "- Use `get_settings(force_reload=True)` after mutating `os.environ` to observe changes at runtime in an idempotent manner.\n",
    "\n",
    "The next code cell runs a safe demo that temporarily unsets adapter-related env vars, reloads settings, and prints which adapters/LLM the framework would use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Baseline: <span style=\"color: #808000; text-decoration-color: #808000\">MODEL_NAME</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mock-model'</span>, SERPAPI key <span style=\"color: #808000; text-decoration-color: #808000\">present</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Baseline: \u001b[33mMODEL_NAME\u001b[0m=\u001b[32m'mock-model'\u001b[0m, SERPAPI key \u001b[33mpresent\u001b[0m=\u001b[3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">During missing-keys demo: <span style=\"color: #808000; text-decoration-color: #808000\">serp_adapter</span>=<span style=\"color: #800080; text-decoration-color: #800080\">SerpAPISearchAdapter</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tav_adapter</span>=<span style=\"color: #800080; text-decoration-color: #800080\">TavilySearchAdapter</span>, <span style=\"color: #808000; text-decoration-color: #808000\">llm</span>=<span style=\"color: #800080; text-decoration-color: #800080\">MockLLM</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "During missing-keys demo: \u001b[33mserp_adapter\u001b[0m=\u001b[35mSerpAPISearchAdapter\u001b[0m, \u001b[33mtav_adapter\u001b[0m=\u001b[35mTavilySearchAdapter\u001b[0m, \u001b[33mllm\u001b[0m=\u001b[35mMockLLM\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">After restore: <span style=\"color: #808000; text-decoration-color: #808000\">MODEL_NAME</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mock-model'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "After restore: \u001b[33mMODEL_NAME\u001b[0m=\u001b[32m'mock-model'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demo: show which adapters/LLM would be used when adapter keys are absent\n",
    "import os\n",
    "from contextlib import contextmanager\n",
    "from research_agent_framework.config import get_settings, get_console\n",
    "from research_agent_framework.adapters.search import from_raw_adapter\n",
    "from research_agent_framework.llm.client import llm_factory, LLMConfig, MockLLM\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "@contextmanager\n",
    "def temp_env_vars(*keys):\n",
    "    \"\"\"Temporarily pop keys from os.environ, restoring them on exit.\"\"\"\n",
    "    saved = {k: os.environ.pop(k, None) for k in keys}\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        for k, v in saved.items():\n",
    "            if v is not None:\n",
    "                os.environ[k] = v\n",
    "\n",
    "# Show baseline\n",
    "settings = get_settings(force_reload=True)\n",
    "console.print(f\"Baseline: MODEL_NAME={settings.model_name!r}, SERPAPI key present={bool(os.environ.get('SERPAPI_API_KEY'))}\")\n",
    "\n",
    "# Temporarily remove adapter keys to simulate missing credentials\n",
    "with temp_env_vars('SERPAPI_API_KEY', 'TAVILY_API_KEY'):\n",
    "    s = get_settings(force_reload=True)\n",
    "    # Use the adapters package factory; provide an empty raw payload and explicit provider\n",
    "    serp_adapter = from_raw_adapter({}, provider='serpapi')\n",
    "    tav_adapter = from_raw_adapter({}, provider='tavily')\n",
    "\n",
    "    # Build a minimal LLMConfig from settings and create an LLM client with fallback\n",
    "    cfg = LLMConfig(api_key=s.llm_api_key or \"\", model=s.model_name or \"mock-model\", temperature=s.model_temperature)\n",
    "    provider = 'mock' if (s.model_name is None or str(s.model_name).startswith('mock')) else str(s.model_name)\n",
    "    try:\n",
    "        llm = llm_factory(provider, cfg)\n",
    "    except Exception:\n",
    "        # Unknown provider or construction failure -> fallback to MockLLM\n",
    "        llm = MockLLM(cfg)\n",
    "\n",
    "    console.print(f\"During missing-keys demo: serp_adapter={serp_adapter.__class__.__name__}, tav_adapter={tav_adapter.__class__.__name__}, llm={llm.__class__.__name__}\")\n",
    "\n",
    "# Restore and show\n",
    "s2 = get_settings(force_reload=True)\n",
    "console.print(f\"After restore: MODEL_NAME={s2.model_name!r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switchboard helper: centralize mock/live toggles (4.3)\n",
    "\n",
    "This small utility centralizes environment-driven toggles used by the notebook and examples. Use the helper to make notebook cells short and declarative â€” change the environment in one place and the helper will consistently report whether the framework will use mocks or live providers.\n",
    "\n",
    "The code cell below demonstrates toggling `FORCE_USE_MOCK` and observing the resolved behavior for search adapters and the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Baseline: <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_search</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_llm</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Baseline: \u001b[33muse_mock_search\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33muse_mock_llm\u001b[0m=\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">After <span style=\"color: #808000; text-decoration-color: #808000\">FORCE_USE_MOCK</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_search</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_llm</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "After \u001b[33mFORCE_USE_MOCK\u001b[0m=\u001b[1;36m1\u001b[0m: \u001b[33muse_mock_search\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33muse_mock_llm\u001b[0m=\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">After restore: <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_search</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_llm</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "After restore: \u001b[33muse_mock_search\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33muse_mock_llm\u001b[0m=\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Switchboard demo cell: toggle FORCE_USE_MOCK and show effective choices\n",
    "import os\n",
    "from research_agent_framework.helpers.switchboard import use_mock_search, use_mock_llm\n",
    "from research_agent_framework.config import get_console, get_settings\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "# Baseline\n",
    "s = get_settings(force_reload=True)\n",
    "console.print(f\"Baseline: use_mock_search={use_mock_search(s)}, use_mock_llm={use_mock_llm(s)}\")\n",
    "\n",
    "# Force use of mocks\n",
    "os.environ['FORCE_USE_MOCK'] = '1'\n",
    "s_forced = get_settings(force_reload=True)\n",
    "console.print(f\"After FORCE_USE_MOCK=1: use_mock_search={use_mock_search(s_forced)}, use_mock_llm={use_mock_llm(s_forced)}\")\n",
    "\n",
    "# Clean up\n",
    "os.environ.pop('FORCE_USE_MOCK', None)\n",
    "s_restored = get_settings(force_reload=True)\n",
    "console.print(f\"After restore: use_mock_search={use_mock_search(s_restored)}, use_mock_llm={use_mock_llm(s_restored)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central switchboard (6.0) - single place to toggle mocks vs live providers\n",
    "\n",
    "This small, editable cell is the recommended place to toggle the environment for the entire notebook when you want to run the examples against live providers. By default the notebook is mock-first (safe and deterministic).\n",
    "\n",
    "Change `FORCE_USE_MOCK` below or set provider-specific keys (`SERPAPI_API_KEY`, `TAVILY_API_KEY`, `MODEL_NAME`) to run with live services. Use `get_settings(force_reload=True)` after editing to apply changes in subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central switchboard applied. Current: FORCE_USE_MOCK= 1 MODEL_NAME= mock-model\n"
     ]
    }
   ],
   "source": [
    "# Central switchboard: edit this cell to toggle mock vs live globally for the notebook\n",
    "# Options:\n",
    "#  - Set FORCE_USE_MOCK=1 to force all mocks\n",
    "#  - Unset FORCE_USE_MOCK and set provider keys (SERPAPI_API_KEY/TAVILY_API_KEY/MODEL_NAME) to use live providers\n",
    "import os\n",
    "# Example: force mocks for all demo cells (safe default)\n",
    "os.environ['FORCE_USE_MOCK'] = os.environ.get('FORCE_USE_MOCK', '1')\n",
    "# Example: to use live providers, uncomment and set real keys here (DO NOT commit secrets)\n",
    "# os.environ.pop('FORCE_USE_MOCK', None)\n",
    "# os.environ['SERPAPI_API_KEY'] = 'sk-...your-key...'\n",
    "# os.environ['TAVILY_API_KEY'] = 'tk-...your-key...'\n",
    "# os.environ['MODEL_NAME'] = 'openai-gpt-4'\n",
    "\n",
    "# Apply settings reload so later cells observe the new environment\n",
    "from research_agent_framework.config import get_settings\n",
    "s = get_settings(force_reload=True)\n",
    "print('Central switchboard applied. Current: FORCE_USE_MOCK=', os.environ.get('FORCE_USE_MOCK'), 'MODEL_NAME=', s.model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 User Clarification and Scoping Demo\n",
    "\n",
    "This section demonstrates how the research agent iteratively refines the user's request using deterministic (mock) responses. The workflow ensures that the agent only proceeds to research after sufficient clarification, mirroring the logic in `research_agent_scope.py` and the corresponding tests.\n",
    "\n",
    "- **7.2 Iterative refinement:** The agent asks clarifying questions until enough information is provided.\n",
    "- **7.3 Scope state capture:** The agent validates and stores the scope state for downstream research.\n",
    "\n",
    "Cells below show the clarification loop and state validation, using mock adapters for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1 - Agent: Thank you for your request. You are looking for the best coffee shops in San Francisco. I have sufficient information to proceed and will now begin researching the top coffee shops in SF for you.\n",
      "Agent is ready to start research or has sufficient info.\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Iterative refinement using deterministic responses (with max turns)\n",
    "from deep_research_from_scratch.research_agent_scope import scope_research, AgentInputState\n",
    "from deep_research_from_scratch.state_scope import AgentState\n",
    "from langchain_core.messages import HumanMessage, AnyMessage\n",
    "from typing import cast\n",
    "\n",
    "# Simulate a user request that needs clarification\n",
    "user_messages = [HumanMessage(content=\"Find the best coffee shops in SF.\")]\n",
    "input_state = AgentInputState(messages=cast(list[AnyMessage], user_messages))\n",
    "\n",
    "max_turns = 3\n",
    "turn = 0\n",
    "while turn < max_turns:\n",
    "    result = scope_research.invoke(input_state)\n",
    "    clarify_msg = result[\"messages\"][-1].content\n",
    "    print(f\"Turn {turn+1} - Agent: {clarify_msg}\")\n",
    "    # Simulate user providing more detail after each clarification\n",
    "    if \"clarify\" in clarify_msg.lower() or \"more detail\" in clarify_msg.lower():\n",
    "        if turn == 0:\n",
    "            user_messages.append(HumanMessage(content=\"I want places open now and not paid.\"))\n",
    "        elif turn == 1:\n",
    "            user_messages.append(HumanMessage(content=\"No cover charge, open now, highest ratings in SOMA.\"))\n",
    "        input_state = AgentInputState(messages=cast(list[AnyMessage], user_messages))\n",
    "        turn += 1\n",
    "    else:\n",
    "        print(\"Agent is ready to start research or has sufficient info.\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"Max turns ({max_turns}) reached. Please provide more specific details to proceed.\")\n",
    "    print(\"Conversation so far:\")\n",
    "    for msg in user_messages:\n",
    "        print(\"User:\", msg.content)\n",
    "    print(\"Last agent message:\", clarify_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "This cell demonstrates how the agent uses deterministic logic to clarify ambiguous user requests. The agent asks for more details if needed, and only proceeds when the scope is sufficiently defined. This mirrors the logic in `research_agent_scope.py` and is validated by tests in `test_research_agent.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Capture scope state object and validation\n",
    "\n",
    "This cell demonstrates how the agent captures the scope state object after clarification and validates its structure, ensuring downstream research steps are well-defined and reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Research brief:</span>                                                                                                    \n",
       "\n",
       "Identify the highest-rated coffee shops in the SOMA neighborhood of San Francisco that are currently open (as of   \n",
       "Friday, September 12, 2025), do not require a cover charge or paid entry, and are accessible to the public. Focus  \n",
       "on user ratings and reviews to determine quality. Only include places that meet all specified criteria. For any    \n",
       "other attributes (such as price range, menu variety, or ambiance), treat them as open considerations unless further\n",
       "specified. Prioritize information from official coffee shop websites, Google Maps, Yelp, and other reputable review\n",
       "platforms for up-to-date hours and ratings.                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mResearch brief:\u001b[0m                                                                                                    \n",
       "\n",
       "Identify the highest-rated coffee shops in the SOMA neighborhood of San Francisco that are currently open (as of   \n",
       "Friday, September 12, 2025), do not require a cover charge or paid entry, and are accessible to the public. Focus  \n",
       "on user ratings and reviews to determine quality. Only include places that meet all specified criteria. For any    \n",
       "other attributes (such as price range, menu variety, or ambiance), treat them as open considerations unless further\n",
       "specified. Prioritize information from official coffee shop websites, Google Maps, Yelp, and other reputable review\n",
       "platforms for up-to-date hours and ratings.                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7.3 Capture scope state object and validate\n",
    "from deep_research_from_scratch.research_agent_scope import scope_research, AgentInputState\n",
    "from deep_research_from_scratch.state_scope import AgentState\n",
    "from langchain_core.messages import HumanMessage, AnyMessage\n",
    "from assertpy import assert_that\n",
    "from typing import cast\n",
    "from research_agent_framework.config import get_console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "# Simulate clarified user request\n",
    "user_messages = [\n",
    "    HumanMessage(content=\"Find the best coffee shops in SF.\"),\n",
    "    HumanMessage(content=\"I want places open now and not paid.\"),\n",
    "    HumanMessage(content=\"No cover charge, open now, highest ratings in SOMA.\")\n",
    "]\n",
    "input_state = AgentInputState(messages=cast(list[AnyMessage], user_messages))\n",
    "result = scope_research.invoke(input_state)\n",
    "\n",
    "# Validate scope state object\n",
    "assert_that(result).contains_key(\"research_brief\")\n",
    "assert_that(result[\"research_brief\"]).is_not_empty()\n",
    "console.print(Markdown(f\"**Research brief:**\\n\\n{result['research_brief']}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Supervisor Policy Demo: Deterministic Multi-Agent Coordination\n",
    "\n",
    "This section demonstrates how the supervisor agent orchestrates multiple research agents using a deterministic policy. The workflow ensures reproducibility and mirrors the logic in `multi_agent_supervisor.py` and the corresponding tests.\n",
    "\n",
    "- **Supervisor Policy:** Coordinates agent actions, assigns tasks, and validates outcomes.\n",
    "- **Deterministic Steps:** Uses mock adapters and fixed agent responses for educational clarity.\n",
    "\n",
    "Cells below show the supervisor's decision-making process and agent coordination, with output rendered using Rich's Markdown for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A1 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Find top-rated coffee shops in SF.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A1 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Find top-rated coffee shops in SF.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A2 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Check which shops are open now.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A2 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Check which shops are open now.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A3 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Filter for no cover charge in SOMA.                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A3 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Filter for no cover charge in SOMA.                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9.1 Supervisor Policy Demo: Deterministic Multi-Agent Coordination\n",
    "from deep_research_from_scratch.multi_agent_supervisor import Supervisor, AgentTask, DeterministicPolicy\n",
    "from deep_research_from_scratch.state_scope import AgentState\n",
    "from research_agent_framework.config import get_console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "# Define mock agent tasks\n",
    "agent_tasks = [\n",
    "    AgentTask(agent_id=\"A1\", description=\"Find top-rated coffee shops in SF.\"),\n",
    "    AgentTask(agent_id=\"A2\", description=\"Check which shops are open now.\"),\n",
    "    AgentTask(agent_id=\"A3\", description=\"Filter for no cover charge in SOMA.\")\n",
    "]\n",
    "\n",
    "# Use deterministic supervisor policy for reproducibility\n",
    "policy = DeterministicPolicy()\n",
    "supervisor = Supervisor(policy=policy)\n",
    "\n",
    "# Run coordination workflow\n",
    "results = supervisor.coordinate(agent_tasks)\n",
    "\n",
    "# Validate and display results\n",
    "for result in results:\n",
    "    assert hasattr(result, \"agent_id\")\n",
    "    assert hasattr(result, \"outcome\")\n",
    "    console.print(Markdown(f\"**Agent {result.agent_id} outcome:**\\n\\n{result.outcome}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Logging Agent Messages and State Transitions\n",
    "\n",
    "This section demonstrates how the supervisor and agents log their messages and state transitions during coordination. Logging is essential for debugging, monitoring, and educational clarity.\n",
    "\n",
    "- **Structured Logging:** Each agent logs its actions and state changes.\n",
    "- **State Transition Tracking:** Supervisor logs before and after coordination steps.\n",
    "\n",
    "Cells below show how logging is integrated into the multi-agent workflow, with output rendered using Rich for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">855196</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Supervisor: Starting coordination\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m855196\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Supervisor: Starting coordination\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.855196+0000 INFO Supervisor: Starting coordination\n",
      "2025-09-12T21:43:35.855196+0000 INFO Supervisor: Starting coordination\n",
      "2025-09-12T21:43:35.855196+0000 INFO Supervisor: Starting coordination\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">863248</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Agent A1 starting: Find top-rated coffee shops in SF.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m863248\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Agent A1 starting: Find top-rated coffee shops in SF.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.863248+0000 INFO Agent A1 starting: Find top-rated coffee shops in SF.\n",
      "2025-09-12T21:43:35.863248+0000 INFO Agent A1 starting: Find top-rated coffee shops in SF.\n",
      "2025-09-12T21:43:35.863248+0000 INFO Agent A1 starting: Find top-rated coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">868908</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Agent A1 finished: Completed: Find top-rated coffee shops in SF.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m868908\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Agent A1 finished: Completed: Find top-rated coffee shops in SF.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.868908+0000 INFO Agent A1 finished: Completed: Find top-rated coffee shops in SF.\n",
      "2025-09-12T21:43:35.868908+0000 INFO Agent A1 finished: Completed: Find top-rated coffee shops in SF.\n",
      "2025-09-12T21:43:35.868908+0000 INFO Agent A1 finished: Completed: Find top-rated coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">878046</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Supervisor: Agent A1 outcome: Completed: Find top-rated coffee shops in SF.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m878046\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Supervisor: Agent A1 outcome: Completed: Find top-rated coffee shops in SF.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.878046+0000 INFO Supervisor: Agent A1 outcome: Completed: Find top-rated coffee shops in SF.\n",
      "2025-09-12T21:43:35.878046+0000 INFO Supervisor: Agent A1 outcome: Completed: Find top-rated coffee shops in SF.\n",
      "2025-09-12T21:43:35.878046+0000 INFO Supervisor: Agent A1 outcome: Completed: Find top-rated coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">885698</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Agent A2 starting: Check which shops are open now.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m885698\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Agent A2 starting: Check which shops are open now.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.885698+0000 INFO Agent A2 starting: Check which shops are open now.\n",
      "2025-09-12T21:43:35.885698+0000 INFO Agent A2 starting: Check which shops are open now.\n",
      "2025-09-12T21:43:35.885698+0000 INFO Agent A2 starting: Check which shops are open now.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">892837</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Agent A2 finished: Completed: Check which shops are open now.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m892837\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Agent A2 finished: Completed: Check which shops are open now.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.892837+0000 INFO Agent A2 finished: Completed: Check which shops are open now.\n",
      "2025-09-12T21:43:35.892837+0000 INFO Agent A2 finished: Completed: Check which shops are open now.\n",
      "2025-09-12T21:43:35.892837+0000 INFO Agent A2 finished: Completed: Check which shops are open now.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">899086</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Supervisor: Agent A2 outcome: Completed: Check which shops are open now.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m899086\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Supervisor: Agent A2 outcome: Completed: Check which shops are open now.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.899086+0000 INFO Supervisor: Agent A2 outcome: Completed: Check which shops are open now.\n",
      "2025-09-12T21:43:35.899086+0000 INFO Supervisor: Agent A2 outcome: Completed: Check which shops are open now.\n",
      "2025-09-12T21:43:35.899086+0000 INFO Supervisor: Agent A2 outcome: Completed: Check which shops are open now.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">903258</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Agent A3 starting: Filter for no cover charge in SOMA.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m903258\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Agent A3 starting: Filter for no cover charge in SOMA.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.903258+0000 INFO Agent A3 starting: Filter for no cover charge in SOMA.\n",
      "2025-09-12T21:43:35.903258+0000 INFO Agent A3 starting: Filter for no cover charge in SOMA.\n",
      "2025-09-12T21:43:35.903258+0000 INFO Agent A3 starting: Filter for no cover charge in SOMA.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">908689</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Agent A3 finished: Completed: Filter for no cover charge in SOMA.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m908689\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Agent A3 finished: Completed: Filter for no cover charge in SOMA.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.908689+0000 INFO Agent A3 finished: Completed: Filter for no cover charge in SOMA.\n",
      "2025-09-12T21:43:35.908689+0000 INFO Agent A3 finished: Completed: Filter for no cover charge in SOMA.\n",
      "2025-09-12T21:43:35.908689+0000 INFO Agent A3 finished: Completed: Filter for no cover charge in SOMA.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">914474</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Supervisor: Agent A3 outcome: Completed: Filter for no cover charge in SOMA.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m914474\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Supervisor: Agent A3 outcome: Completed: Filter for no cover charge in SOMA.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.914474+0000 INFO Supervisor: Agent A3 outcome: Completed: Filter for no cover charge in SOMA.\n",
      "2025-09-12T21:43:35.914474+0000 INFO Supervisor: Agent A3 outcome: Completed: Filter for no cover charge in SOMA.\n",
      "2025-09-12T21:43:35.914474+0000 INFO Supervisor: Agent A3 outcome: Completed: Filter for no cover charge in SOMA.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-12T<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:43:35</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">920462</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0000</span> INFO Supervisor: Coordination complete\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-12T\u001b[1;92m21:43:35\u001b[0m.\u001b[1;36m920462\u001b[0m+\u001b[1;36m0000\u001b[0m INFO Supervisor: Coordination complete\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12T21:43:35.920462+0000 INFO Supervisor: Coordination complete\n",
      "2025-09-12T21:43:35.920462+0000 INFO Supervisor: Coordination complete\n",
      "2025-09-12T21:43:35.920462+0000 INFO Supervisor: Coordination complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A1 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Find top-rated coffee shops in SF.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A1 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Find top-rated coffee shops in SF.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A2 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Check which shops are open now.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A2 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Check which shops are open now.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A3 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Filter for no cover charge in SOMA.                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A3 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Filter for no cover charge in SOMA.                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9.2 Logging Agent Messages and State Transitions (with logger injection demo)\n",
    "from deep_research_from_scratch.multi_agent_supervisor import Supervisor, AgentTask, DeterministicPolicy, LoggingSupervisor, LoggingAgentTask\n",
    "from research_agent_framework.config import get_console, get_logger\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = get_console()\n",
    "logger = get_logger()\n",
    "\n",
    "# Inject logger into agent tasks and supervisor for reproducible logging\n",
    "agent_tasks = [\n",
    "    LoggingAgentTask(agent_id=\"A1\", description=\"Find top-rated coffee shops in SF.\", logger=logger),\n",
    "    LoggingAgentTask(agent_id=\"A2\", description=\"Check which shops are open now.\", logger=logger),\n",
    "    LoggingAgentTask(agent_id=\"A3\", description=\"Filter for no cover charge in SOMA.\", logger=logger)\n",
    "]\n",
    "supervisor = LoggingSupervisor(logger=logger)\n",
    "results = supervisor.coordinate(agent_tasks)\n",
    "\n",
    "for result in results:\n",
    "    console.print(Markdown(f\"**Agent {result.agent_id} outcome:**\\n\\n{result.outcome}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.0 Research Compression and Synthesis\n",
    "\n",
    "This section demonstrates how to compress and synthesize research findings using deterministic logic (MockLLM) and structured outputs. The workflow mirrors the agent's compression node and aligns with tests in `test_supervisor_policy_deterministic.py` and `test_end_to_end_flow.py`.\n",
    "\n",
    "- **10.1 Compression strategy:** Uses a Jinja2 template and MockLLM to compress findings.\n",
    "- **10.2 Synthesis:** Produces structured objects for downstream reporting.\n",
    "- **10.3 Validation:** Validates outputs and displays with rich output.\n",
    "\n",
    "Cells below show the compression logic, synthesis, and output validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Compressed Research Summary:</span>                                                                                       \n",
       "\n",
       "mock response for:                                                                                                 \n",
       "\n",
       "\"\"\" Compress the following research findings and notes into a concise, comprehensive summary suitable for reporting\n",
       "and further synthesis.                                                                                             \n",
       "\n",
       "Guidelines:                                                                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Do NOT lose any details, facts, names, numbers, or specific findings                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Do NOT filter out information that seems relevant to the research topic                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Organize the information in a cleaner format but keep all the substance                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Include ALL sources and citations found during research                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Remember this research was conducted to answer the specific question above                                      \n",
       "\n",
       "Today's date is 2025-09-12.                                                                                        \n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.                                                       \n",
       "\n",
       "\n",
       "Please compress and synthesize the above findings into a single, well-structured summary. \"\"\"                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mCompressed Research Summary:\u001b[0m                                                                                       \n",
       "\n",
       "mock response for:                                                                                                 \n",
       "\n",
       "\"\"\" Compress the following research findings and notes into a concise, comprehensive summary suitable for reporting\n",
       "and further synthesis.                                                                                             \n",
       "\n",
       "Guidelines:                                                                                                        \n",
       "\n",
       "\u001b[1;33m â€¢ \u001b[0mDo NOT lose any details, facts, names, numbers, or specific findings                                            \n",
       "\u001b[1;33m â€¢ \u001b[0mDo NOT filter out information that seems relevant to the research topic                                         \n",
       "\u001b[1;33m â€¢ \u001b[0mOrganize the information in a cleaner format but keep all the substance                                         \n",
       "\u001b[1;33m â€¢ \u001b[0mInclude ALL sources and citations found during research                                                         \n",
       "\u001b[1;33m â€¢ \u001b[0mRemember this research was conducted to answer the specific question above                                      \n",
       "\n",
       "Today's date is 2025-09-12.                                                                                        \n",
       "\n",
       "\n",
       "\n",
       "\u001b[1;33m â€¢ \u001b[0mBlue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.                                            \n",
       "\u001b[1;33m â€¢ \u001b[0mSightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.                                         \n",
       "\u001b[1;33m â€¢ \u001b[0mVerve Coffee: 4.5 stars, open now, SOMA, no cover charge.                                                       \n",
       "\n",
       "\n",
       "Please compress and synthesize the above findings into a single, well-structured summary. \"\"\"                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10.1 Compression strategy with MockLLM\n",
    "from research_agent_framework.llm.client import MockLLM, LLMConfig\n",
    "from research_agent_framework.prompts import renderer\n",
    "from research_agent_framework.config import get_console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = get_console()\n",
    "mock_config = LLMConfig(api_key=\"test\", model=\"mock-model\")\n",
    "mock_llm = MockLLM(mock_config)\n",
    "\n",
    "# Example research brief and notes\n",
    "research_brief = 'Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.'\n",
    "notes = [\n",
    "    'Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.',\n",
    "    'Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.',\n",
    "    'Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.'\n",
    "]\n",
    "\n",
    "# Render compression prompt using Jinja2 template\n",
    "from datetime import date\n",
    "compression_prompt = renderer.render_template('compress_research.j2', {\n",
    "    'date': date.today().isoformat(),\n",
    "    'research_brief': research_brief,\n",
    "    'notes': notes\n",
    "})\n",
    "\n",
    "# Use MockLLM to compress findings\n",
    "import asyncio\n",
    "summary = asyncio.run(mock_llm.generate(compression_prompt))\n",
    "console.print(Markdown(f'**Compressed Research Summary:**\\n\\n{summary}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "This cell demonstrates how the agent compresses research findings using a Jinja2 template and MockLLM for deterministic output. The summary is rendered with rich Markdown for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">EvalResult:</span>                                                                                                        \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "task_id='synth-001' success=True score=0.95 feedback='mock response for: \\n\\n\"\"\"\\nCompress the following research  \n",
       "findings and notes into a concise, comprehensive summary suitable for reporting and further                        \n",
       "synthesis.\\n\\nGuidelines:\\n- Do NOT lose any details, facts, names, numbers, or specific findings\\n- Do NOT filter \n",
       "out information that seems relevant to the research topic\\n- Organize the information in a cleaner format but keep \n",
       "all the substance\\n- Include ALL sources and citations found during research\\n- Remember this research was         \n",
       "conducted to answer the specific question above\\n\\nToday's date is 2025-09-12.\\n\\n\\nFind the best coffee shops in  \n",
       "SF with no cover charge, open now, highest ratings in SOMA.\\n&lt;/Research Brief&gt;\\n\\n\\n\\n- Blue Bottle Coffee: 4.7    \n",
       "stars, open now, free WiFi, no cover charge.\\n\\n- Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover  \n",
       "charge.\\n\\n- Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.\\n\\n\\n\\nPlease compress and synthesize the   \n",
       "above findings into a single, well-structured summary.\\n\"\"\"' details={'notes': 'Blue Bottle Coffee: 4.7 stars, open\n",
       "now, free WiFi, no cover charge.\\nSightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.\\nVerve   \n",
       "Coffee: 4.5 stars, open now, SOMA, no cover charge.'}                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEvalResult:\u001b[0m                                                                                                        \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "task_id='synth-001' success=True score=0.95 feedback='mock response for: \\n\\n\"\"\"\\nCompress the following research  \n",
       "findings and notes into a concise, comprehensive summary suitable for reporting and further                        \n",
       "synthesis.\\n\\nGuidelines:\\n- Do NOT lose any details, facts, names, numbers, or specific findings\\n- Do NOT filter \n",
       "out information that seems relevant to the research topic\\n- Organize the information in a cleaner format but keep \n",
       "all the substance\\n- Include ALL sources and citations found during research\\n- Remember this research was         \n",
       "conducted to answer the specific question above\\n\\nToday's date is 2025-09-12.\\n\\n\\nFind the best coffee shops in  \n",
       "SF with no cover charge, open now, highest ratings in SOMA.\\n</Research Brief>\\n\\n\\n\\n- Blue Bottle Coffee: 4.7    \n",
       "stars, open now, free WiFi, no cover charge.\\n\\n- Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover  \n",
       "charge.\\n\\n- Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.\\n\\n\\n\\nPlease compress and synthesize the   \n",
       "above findings into a single, well-structured summary.\\n\"\"\"' details={'notes': 'Blue Bottle Coffee: 4.7 stars, open\n",
       "now, free WiFi, no cover charge.\\nSightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.\\nVerve   \n",
       "Coffee: 4.5 stars, open now, SOMA, no cover charge.'}                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10.2 Synthesize findings into structured objects\n",
    "from research_agent_framework.models import EvalResult\n",
    "from assertpy import assert_that\n",
    "\n",
    "# Simulate synthesis: wrap summary into EvalResult\n",
    "eval_result = EvalResult(\n",
    "    task_id='synth-001',\n",
    "    success=True,\n",
    "    score=0.95,\n",
    "    feedback=str(summary),\n",
    "    details={'notes': '\\n'.join(notes)}\n",
    " )\n",
    "# Validate structured output\n",
    "assert_that(eval_result).is_instance_of(EvalResult)\n",
    "assert_that(eval_result.feedback).contains('mock response for:')\n",
    "console.print(Markdown(f'**EvalResult:**\\n\\n{eval_result}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "This cell shows how compressed findings are synthesized into a structured EvalResult object, validated for type and content, and displayed with rich output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.0 Final Report Generation\n",
    "\n",
    "This section demonstrates how to assemble the final research report, render it with rich output, and provide a downloadable artifact. The workflow uses deterministic logic and aligns with renderer and output tests.\n",
    "\n",
    "- **11.1 Assemble report sections and metadata**\n",
    "- **11.2 Verify formatting against renderer tests**\n",
    "- **11.3 Provide downloadable artifact (markdown export)\n",
    "\n",
    "Cells below show the report assembly, rendering, and export logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Rendered final_report_prompt start ---\n",
      "\n",
      "\n",
      "# Final Research Report\n",
      "\n",
      "## Research Brief\n",
      "Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.\n",
      "\n",
      "## Findings\n",
      "\n",
      "- Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.\n",
      "\n",
      "- Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.\n",
      "\n",
      "- Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.\n",
      "\n",
      "\n",
      "---\n",
      "Today's date is 2025-09-12.\n",
      "\n",
      "\n",
      "\n",
      "--- Rendered final_report_prompt end ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Final Research Report:</span>                                                                                             \n",
       "\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ                                              <span style=\"font-weight: bold\">Final Research Report</span>                                              â”ƒ\n",
       "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\n",
       "\n",
       "\n",
       "                                                  <span style=\"font-weight: bold; text-decoration: underline\">Research Brief</span>                                                   \n",
       "\n",
       "Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.                          \n",
       "\n",
       "\n",
       "                                                     <span style=\"font-weight: bold; text-decoration: underline\">Findings</span>                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> â€¢ </span>Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.                                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>\n",
       "Today's date is 2025-09-12.                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mFinal Research Report:\u001b[0m                                                                                             \n",
       "\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ                                              \u001b[1mFinal Research Report\u001b[0m                                              â”ƒ\n",
       "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\n",
       "\n",
       "\n",
       "                                                  \u001b[1;4mResearch Brief\u001b[0m                                                   \n",
       "\n",
       "Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.                          \n",
       "\n",
       "\n",
       "                                                     \u001b[1;4mFindings\u001b[0m                                                      \n",
       "\n",
       "\u001b[1;33m â€¢ \u001b[0mBlue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.                                            \n",
       "\u001b[1;33m â€¢ \u001b[0mSightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.                                         \n",
       "\u001b[1;33m â€¢ \u001b[0mVerve Coffee: 4.5 stars, open now, SOMA, no cover charge.                                                       \n",
       "\n",
       "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
       "Today's date is 2025-09-12.                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.1 Assemble report sections and metadata\n",
    "from research_agent_framework.prompts import renderer\n",
    "from research_agent_framework.llm.client import MockLLM, LLMConfig\n",
    "from research_agent_framework.config import get_console\n",
    "from rich.markdown import Markdown\n",
    "from datetime import date\n",
    "\n",
    "console = get_console()\n",
    "mock_config = LLMConfig(api_key=\"test\", model=\"mock-model\")\n",
    "mock_llm = MockLLM(mock_config)\n",
    "\n",
    "# Example: assemble report sections\n",
    "report_metadata = {\n",
    "    'date': date.today().isoformat(),\n",
    "    'research_brief': 'Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.',\n",
    "    'findings': [\n",
    "        'Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.',\n",
    "        'Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.',\n",
    "        'Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.'\n",
    "    ],\n",
    "    'sources': []\n",
    "}\n",
    "\n",
    "# Render final report using Jinja2 template\n",
    "final_report_prompt = renderer.render_template('final_report_generation_prompt.j2', report_metadata)\n",
    "\n",
    "# DEBUG: show the rendered prompt so we can verify it contains the report content and not an agent prompt\n",
    "print('--- Rendered final_report_prompt start ---')\n",
    "print(final_report_prompt)\n",
    "print('--- Rendered final_report_prompt end ---')\n",
    "\n",
    "# Sanitize prompt: remove any angle-bracket instruction tokens that may have leaked in\n",
    "import re\n",
    "sanitized_prompt = re.sub(r'<[^>]+>', '', final_report_prompt)\n",
    "# Collapse repeated blank lines for cleanliness\n",
    "sanitized_prompt = re.sub(r'\\n{3,}', '\\n\\n', sanitized_prompt).strip()\n",
    "\n",
    "# By default, use the rendered template as the final report to ensure no agent instructions\n",
    "# If you want to exercise the LLM, set `use_llm = True` (keeps deterministic default for demos/tests)\n",
    "use_llm = False\n",
    "import asyncio\n",
    "if use_llm:\n",
    "    final_report = asyncio.run(mock_llm.generate(sanitized_prompt))\n",
    "else:\n",
    "    final_report = sanitized_prompt\n",
    "\n",
    "console.print(Markdown(f'**Final Research Report:**\\n\\n{final_report}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Report formatting validated against renderer tests.</span>                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mReport formatting validated against renderer tests.\u001b[0m                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.2 Verify formatting against renderer tests\n",
    "from assertpy import assert_that\n",
    "\n",
    "# Validate that the final report contains expected structure\n",
    "assert_that(final_report).contains('# Final Research Report')\n",
    "assert_that(final_report).contains('Findings')\n",
    "console.print(Markdown(f'**Report formatting validated against renderer tests.**'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">âœ… Final report saved as final_research_report.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mâœ… Final report saved as final_research_report.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.3 Provide downloadable artifact (markdown export)\n",
    "import os\n",
    "\n",
    "# Save the final report as a markdown file\n",
    "output_path = 'final_research_report.md'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(final_report)\n",
    "\n",
    "console.print(f'[bold green]âœ… Final report saved as {output_path}[/bold green]')\n",
    "\n",
    "# Test: ensure the saved file contains the actual report, not the prompt\n",
    "with open(output_path, 'r', encoding='utf-8') as f:\n",
    "    saved_content = f.read()\n",
    "assert saved_content.startswith('# Final Research Report'), \"Report does not start with expected header!\"\n",
    "assert 'Findings' in saved_content, \"Report does not contain a findings section!\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
