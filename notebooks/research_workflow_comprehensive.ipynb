{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-1-92cdcb33"
   },
   "source": [
    "# Comprehensive Educational Research Notebook\n",
    "\n",
    "This notebook demonstrates a complete multi-agent research system that combines:\n",
    "\n",
    "- **Full Research Workflow** (from `5_full_agent.ipynb`): Complete end-to-end research process\n",
    "- **MCP Integration** (from `3_research_agent_mcp.ipynb`): Model Context Protocol for tool access\n",
    "- **Test-Synchronized Examples** (from `0_consolidated_research_agent.ipynb`): Deterministic demonstrations\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "\n",
    "1. **System Architecture**: How multi-agent research systems are structured\n",
    "2. **MCP Integration**: How to use Model Context Protocol for tool access\n",
    "3. **LLM Impact**: How different prompts and LLM settings affect research quality\n",
    "4. **Workflow Orchestration**: How LangGraph coordinates complex research workflows\n",
    "5. **Test-Driven Development**: How to build reliable, testable AI systems\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic understanding of Python and async programming\n",
    "- Familiarity with Jupyter notebooks\n",
    "- Understanding of LLMs and their capabilities\n",
    "- Basic knowledge of agent-based systems\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "This notebook is organized into distinct sections, each building upon the previous:\n",
    "\n",
    "1. **Bootstrap & Setup**: Environment configuration and initialization\n",
    "2. **Core Components**: Understanding the building blocks\n",
    "3. **MCP Integration**: Tool access and async operations\n",
    "4. **Research Workflow**: Complete end-to-end process\n",
    "5. **LLM Impact Analysis**: Understanding prompt and model effects\n",
    "6. **Test Synchronization**: Ensuring reliability and reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "id": "#VSC-auto-2-6177d284"
   },
   "outputs": [],
   "source": [
    "# Use the centralized notebook bootstrap helper to ensure src is on sys.path\n",
    "# and to run project bootstrap. This keeps notebooks DRY.\n",
    "#\n",
    "# In some environments the `notebooks` directory is not an importable package\n",
    "# (for example, when running the notebook from the repo root without an __init__.py).\n",
    "# To avoid `ModuleNotFoundError: No module named 'notebooks'`, we load the\n",
    "# helper by file path using importlib so the notebook works regardless.\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "def _locate_nb_bootstrap():\n",
    "    candidates = []\n",
    "    try:\n",
    "        candidates.append(Path(__file__).parent)\n",
    "    except NameError:\n",
    "        pass\n",
    "    candidates.append(Path.cwd())\n",
    "    for c in candidates:\n",
    "        p = c / 'nb_bootstrap.py'\n",
    "        if p.exists():\n",
    "            return p\n",
    "    for parent in [Path.cwd()] + list(Path.cwd().parents):\n",
    "        p = parent / 'notebooks' / 'nb_bootstrap.py'\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise ImportError('Could not locate nb_bootstrap.py relative to notebook or cwd')\n",
    "helper_path = _locate_nb_bootstrap()\n",
    "spec = importlib.util.spec_from_file_location('nb_bootstrap', str(helper_path))\n",
    "if spec is None or spec.loader is None:\n",
    "    raise ImportError(f'Failed to load nb_bootstrap from {helper_path!s}: spec or loader is None')\n",
    "nb_bootstrap = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(nb_bootstrap)\n",
    "ensure_src_and_bootstrap = nb_bootstrap.ensure_src_and_bootstrap\n",
    "\n",
    "# Returns (settings, console, logger)\n",
    "settings, console, logger = ensure_src_and_bootstrap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "#VSC-auto-3-c6b41274"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 17:32:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>std<span style=\"font-weight: bold\">]</span> This is an info message with RichHandler.                       <a href=\"file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1973489552.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 17:32:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mstd\u001b[1m]\u001b[0m This is an info message with RichHandler.                       \u001b]8;id=237181;file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py\u001b\\\u001b[2m1973489552.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=387901;file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 17:32:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:32:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">770</span> INFO <span style=\"font-weight: bold\">[</span>std<span style=\"font-weight: bold\">]</span> This is an info message with       <a href=\"file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1973489552.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         RichHandler.                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 17:32:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m17:32:36\u001b[0m,\u001b[1;36m770\u001b[0m INFO \u001b[1m[\u001b[0mstd\u001b[1m]\u001b[0m This is an info message with       \u001b]8;id=134167;file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py\u001b\\\u001b[2m1973489552.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=187155;file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         RichHandler.                                                          \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> <span style=\"font-weight: bold\">[</span>std<span style=\"font-weight: bold\">]</span> This is a warning message with RichHandler.                     <a href=\"file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1973489552.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m \u001b[1m[\u001b[0mstd\u001b[1m]\u001b[0m This is a warning message with RichHandler.                     \u001b]8;id=699264;file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py\u001b\\\u001b[2m1973489552.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=142586;file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:32:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">775</span> WARNING <span style=\"font-weight: bold\">[</span>std<span style=\"font-weight: bold\">]</span> This is a warning message with  <a href=\"file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1973489552.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         RichHandler.                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m \u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m17:32:36\u001b[0m,\u001b[1;36m775\u001b[0m WARNING \u001b[1m[\u001b[0mstd\u001b[1m]\u001b[0m This is a warning message with  \u001b]8;id=86086;file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py\u001b\\\u001b[2m1973489552.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=842619;file://C:\\Users\\daveg\\AppData\\Local\\Temp\\ipykernel_13308\\1973489552.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         RichHandler.                                                          \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:36.779 | INFO     | __main__:&lt;module&gt;:18 - [loguru] This is an info message with Rich color.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:36.779 | INFO     | __main__:<module>:18 - [loguru] This is an info message with Rich color.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:36.781 | WARNING  | __main__:&lt;module&gt;:19 - [loguru] This is a warning message with Rich color.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:36.781 | WARNING  | __main__:<module>:19 - [loguru] This is a warning message with Rich color.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try both loggers: std logging with RichHandler and Loguru with Rich sink\n",
    "import logging\n",
    "from rich.logging import RichHandler\n",
    "from research_agent_framework.config import get_logger, get_console\n",
    "from loguru import logger as loguru_logger\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "# Std logging with RichHandler\n",
    "std_logger = logging.getLogger(\"rich_std_demo\")\n",
    "std_logger.setLevel(\"INFO\")\n",
    "if not any(isinstance(h, RichHandler) for h in std_logger.handlers):\n",
    "    std_logger.addHandler(RichHandler(console=console, rich_tracebacks=True))\n",
    "std_logger.info(\"[std] This is an info message with RichHandler.\")\n",
    "std_logger.warning(\"[std] This is a warning message with RichHandler.\")\n",
    "\n",
    "# Loguru with Rich sink (configured by bootstrap)\n",
    "loguru_logger.info(\"[loguru] This is an info message with Rich color.\")\n",
    "loguru_logger.warning(\"[loguru] This is a warning message with Rich color.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-4-5e191bcd"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-5-bb0d3425"
   },
   "source": [
    "## Section 1: Bootstrap & Setup\n",
    "\n",
    "The first step in any robust AI system is proper initialization and configuration. This section demonstrates:\n",
    "\n",
    "- **Environment Setup**: Loading configuration and setting up logging\n",
    "- **Path Management**: Ensuring proper imports and module discovery\n",
    "- **Bootstrap Process**: Initializing the research framework\n",
    "- **Console Configuration**: Setting up rich output for educational purposes\n",
    "\n",
    "### Why Bootstrap Matters\n",
    "\n",
    "Bootstrap ensures that:\n",
    "1. Environment variables are loaded correctly\n",
    "2. Logging is configured for debugging and monitoring\n",
    "3. Console output is formatted for readability\n",
    "4. All dependencies are properly initialized\n",
    "5. Error handling is set up with rich tracebacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-6-b91b2126"
   },
   "source": [
    "## TODO Anchors and Test Cross‑links\n",
    "\n",
    "- [ ] Section 2: Core Components — see `tests/test_research_agent.py`\n",
    "- [ ] Section 3: MCP Integration — see `tests/test_renderer_rich.py`\n",
    "- [ ] Section 4: Research Workflow — see `tests/test_end_to_end_flow.py`\n",
    "- [ ] Section 5: LLM Impact Analysis — see `tests/test_llm_mock.py`\n",
    "- [ ] Section 6: Test Synchronization — see `tests/test_renderer.py`\n",
    "- [ ] Search Adapters (SerpAPI/Tavily) — see `tests/test_serpapi_adapter.py`, `tests/test_tavily_adapter.py`, `tests/test_serpapi_and_tavily_adapters.py`, `tests/test_adapters*.py`\n",
    "- [ ] Supervisor Policy Demo — see `tests/test_supervisor_policy.py`, `tests/test_supervisor_policy_deterministic.py`\n",
    "- [ ] Bootstrap & Config Walkthrough — see `tests/test_bootstrap.py`, `tests/test_bootstrap_wiring.py`, `tests/test_config.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "#VSC-auto-7-482ccc78"
   },
   "outputs": [],
   "source": [
    "# Use centralized helper to bootstrap the project and obtain common handles\n",
    "# Load helper by file path to avoid depending on 'notebooks' being an importable package\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "def _locate_nb_bootstrap():\n",
    "    candidates = []\n",
    "    try:\n",
    "        candidates.append(Path(__file__).parent)\n",
    "    except NameError:\n",
    "        pass\n",
    "    candidates.append(Path.cwd())\n",
    "    for c in candidates:\n",
    "        p = c / 'nb_bootstrap.py'\n",
    "        if p.exists():\n",
    "            return p\n",
    "    for parent in [Path.cwd()] + list(Path.cwd().parents):\n",
    "        p = parent / 'notebooks' / 'nb_bootstrap.py'\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise ImportError('Could not locate nb_bootstrap.py relative to notebook or cwd')\n",
    "helper_path = _locate_nb_bootstrap()\n",
    "spec = importlib.util.spec_from_file_location('nb_bootstrap', str(helper_path))\n",
    "if spec is None or spec.loader is None:\n",
    "    raise ImportError(f'Failed to load nb_bootstrap from {helper_path!s}: spec or loader is None')\n",
    "nb_bootstrap = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(nb_bootstrap)\n",
    "ensure_src_and_bootstrap = nb_bootstrap.ensure_src_and_bootstrap\n",
    "\n",
    "settings, console, logger = ensure_src_and_bootstrap()\n",
    "\n",
    "def nb_console():\n",
    "    \"\"\"Return the project's shared `Console` instance via `get_console()`.\"\"\"\n",
    "    try:\n",
    "        return settings.console\n",
    "    except Exception:\n",
    "        from rich.console import Console\n",
    "        return Console()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-8-ee749b29"
   },
   "source": [
    "### Bootstrap Process Demonstration\n",
    "\n",
    "Now let's run the bootstrap process and see what it initializes. This demonstrates how a production AI system should start up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "#VSC-auto-9-5ccd6b6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Running bootstrap process<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Running bootstrap process\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────── Bootstrap Status ─────────────────╮\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Bootstrap Complete</span>                             │\n",
       "│                                                   │\n",
       "│ The research framework has been initialized with: │\n",
       "│ • Environment variables loaded                    │\n",
       "│ • Logging configured (console sink)               │\n",
       "│ • Console formatting enabled                      │\n",
       "│ • Error handling set up                           │\n",
       "╰───────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────── Bootstrap Status ─────────────────╮\n",
       "│ \u001b[1;32m✅ Bootstrap Complete\u001b[0m                             │\n",
       "│                                                   │\n",
       "│ The research framework has been initialized with: │\n",
       "│ • Environment variables loaded                    │\n",
       "│ • Logging configured (console sink)               │\n",
       "│ • Console formatting enabled                      │\n",
       "│ • Error handling set up                           │\n",
       "╰───────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Framework Configuration                               </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Component            </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Status          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Details                                  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Environment          </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ✅ Loaded       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Variables from .env file (if present)    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Logging              </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ✅ Configured   </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Loguru wired to Rich Console             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Console              </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ✅ Ready        </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Rich formatting enabled                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Error Handling       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ✅ Active       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Rich tracebacks installed                </span>│\n",
       "└──────────────────────┴─────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Framework Configuration                               \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mComponent           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mStatus         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mDetails                                 \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mEnvironment         \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m✅ Loaded      \u001b[0m\u001b[32m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mVariables from .env file (if present)   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mLogging             \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m✅ Configured  \u001b[0m\u001b[32m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mLoguru wired to Rich Console            \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mConsole             \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m✅ Ready       \u001b[0m\u001b[32m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mRich formatting enabled                 \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mError Handling      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m✅ Active      \u001b[0m\u001b[32m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mRich tracebacks installed               \u001b[0m\u001b[37m \u001b[0m│\n",
       "└──────────────────────┴─────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bootstrap the research framework\n",
    "# This initializes logging, console, and environment configuration\n",
    "from research_agent_framework.bootstrap import bootstrap\n",
    "from research_agent_framework.config import get_settings, get_console, get_logger\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "\n",
    "# Run bootstrap to configure the environment\n",
    "console.print(\"🔄 Running bootstrap process...\")\n",
    "bootstrap()\n",
    "\n",
    "# Get the configured settings, console, and logger\n",
    "settings = get_settings()\n",
    "console = settings.console # get_console()\n",
    "logger = settings.logger # get_logger()\n",
    "\n",
    "# Display bootstrap information\n",
    "console.print(Panel(\n",
    "    \"[bold green]✅ Bootstrap Complete[/bold green]\\n\\n\"\n",
    "    \"The research framework has been initialized with:\\n\"\n",
    "    \"• Environment variables loaded\\n\"\n",
    "    \"• Logging configured (console sink)\\n\"\n",
    "    \"• Console formatting enabled\\n\"\n",
    "    \"• Error handling set up\",\n",
    "    title=\"Bootstrap Status\",\n",
    "    expand=False\n",
    "))\n",
    "\n",
    "# Show configuration details\n",
    "config_table = Table(title=\"Framework Configuration\", show_header=True, header_style=\"bold magenta\")\n",
    "config_table.add_column(\"Component\", style=\"cyan\", width=20)\n",
    "config_table.add_column(\"Status\", style=\"green\", width=15)\n",
    "config_table.add_column(\"Details\", style=\"white\", width=40)\n",
    "\n",
    "config_table.add_row(\"Environment\", \"✅ Loaded\", \"Variables from .env file (if present)\")\n",
    "config_table.add_row(\"Logging\", \"✅ Configured\", \"Loguru wired to Rich Console\")\n",
    "config_table.add_row(\"Console\", \"✅ Ready\", \"Rich formatting enabled\")\n",
    "config_table.add_row(\"Error Handling\", \"✅ Active\", \"Rich tracebacks installed\")\n",
    "\n",
    "console.print(config_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "#VSC-auto-10-12a839b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:36.812 | INFO     | research_agent_framework.logging:info:92 - Bootstrap complete. Environment, </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">console, and logging configured.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:36.812 | INFO     | research_agent_framework.logging:info:92 - Bootstrap complete. Environment, \u001b[0m\n",
       "\u001b[1;35mconsole, and logging configured.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging: after bootstrap\n",
    "logger.info(\"Bootstrap complete. Environment, console, and logging configured.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-11-74df8fbf"
   },
   "source": [
    "### Configuration impact on behavior and logging\n",
    "\n",
    "This section explains how changing settings (env vars) impacts runtime:\n",
    "\n",
    "- `model_name` and `model_temperature` influence prompt behavior and deterministic outputs.\n",
    "- `LOGGING__LEVEL` and `LOGGING__FMT` change the logging verbosity and format; the `Settings.logger` property reflects changes when `get_settings(force_reload=True)` is used.\n",
    "- `enable_tracing` toggles optional tracing hooks (visualizations guarded by env).\n",
    "\n",
    "Below is a safe example demonstrating how to reload settings at runtime and observe logger level changes without restarting the notebook.\n",
    "\n",
    "Note: This example mutates process environment variables temporarily and reloads `Settings` with `force_reload=True` to illustrate effects in a deterministic demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "#VSC-auto-12-35bfe030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reload: logging.level= INFO\n",
      "After reload: logging.level= DEBUG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:36.826 | INFO     | research_agent_framework.logging:info:92 - This is an info message (should </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">always show at INFO/DEBUG)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:36.826 | INFO     | research_agent_framework.logging:info:92 - This is an info message (should \u001b[0m\n",
       "\u001b[1;35malways show at INFO/DEBUG)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:36.826097-0700 INFO This is an info message (should always show at INFO/DEBUG)\n",
      "2025-09-13T17:32:36.828321-0700 DEBUG This is a debug message (visible only when level=DEBUG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored: logging.level= INFO\n"
     ]
    }
   ],
   "source": [
    "# Demonstration: change logging level via env and reload settings\n",
    "import os\n",
    "from research_agent_framework.config import get_settings, get_logger\n",
    "\n",
    "# Show current logging level\n",
    "settings = get_settings()\n",
    "print(\"Before reload: logging.level=\", settings.logging.level)\n",
    "\n",
    "# Temporarily set environment to DEBUG and reload\n",
    "os.environ[\"LOGGING__LEVEL\"] = \"DEBUG\"\n",
    "settings = get_settings(force_reload=True)\n",
    "print(\"After reload: logging.level=\", settings.logging.level)\n",
    "\n",
    "# Acquire logger and show that level reflects setting\n",
    "logger = get_logger()\n",
    "logger.info(\"This is an info message (should always show at INFO/DEBUG)\")\n",
    "logger.debug(\"This is a debug message (visible only when level=DEBUG)\")\n",
    "\n",
    "# Clean up: restore env and reload to original for deterministic notebook runs\n",
    "os.environ.pop(\"LOGGING__LEVEL\", None)\n",
    "settings = get_settings(force_reload=True)\n",
    "print(\"Restored: logging.level=\", settings.logging.level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "#VSC-auto-13-3737c680"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:36.847 | INFO     | research_agent_framework.logging:info:92 - Reloaded settings: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">logging.level=INFO</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:36.847 | INFO     | research_agent_framework.logging:info:92 - Reloaded settings: \u001b[0m\n",
       "\u001b[1;35mlogging.level=INFO\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:36.847809-0700 INFO Reloaded settings: logging.level=INFO\n"
     ]
    }
   ],
   "source": [
    "# Logging: config reload demo\n",
    "logger.info(f\"Reloaded settings: logging.level={settings.logging.level}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-14-8fed807c"
   },
   "source": [
    "## Architecture & Technologies (Brief Overview)\n",
    "\n",
    "- **Settings & Bootstrap**: `Settings` (Pydantic) loads env; `bootstrap()` enables rich tracebacks and wires Loguru → Rich `Console`.\n",
    "- **Logging**: `LoggingConfig` fields (`level`, `fmt`, `backend`) drive a lazy `logger` property; helpers delegate to the same instances.\n",
    "- **Agents & Models**: Agents coordinate research steps; Pydantic models (`SerpResult`, `Scope`, etc.) provide typed state.\n",
    "- **Adapters**: Search adapters (SerpAPI/Tavily) expose deterministic stubs with optional live paths.\n",
    "- **Prompts/Renderer**: Jinja templates rendered with rich-markdown output for clarity.\n",
    "- **Tests as Specs**: Notebook sections mirror `tests/` behaviors for deterministic, reproducible demos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-15-ed9f44e5"
   },
   "source": [
    "## Architecture Diagram (Components)\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "  subgraph Agents\n",
    "    A[Research Agent]\n",
    "    S[Scoping Agent]\n",
    "    SP[Supervisor]\n",
    "  end\n",
    "\n",
    "  subgraph Framework\n",
    "    CFG[Settings]\n",
    "    LCFG[LoggingConfig]\n",
    "    CON[Console]\n",
    "    LGR[Logger]\n",
    "    PR[Prompt Renderer]\n",
    "    LLM[LLM Client]\n",
    "  end\n",
    "\n",
    "  subgraph Adapters\n",
    "    SERP[SerpAPI Adapter]\n",
    "    TAV[Tavily Adapter]\n",
    "  end\n",
    "\n",
    "  A --> PR\n",
    "  A --> LLM\n",
    "  A --> SERP\n",
    "  A --> TAV\n",
    "  S --> PR\n",
    "  SP --> A\n",
    "  SP --> S\n",
    "\n",
    "  CFG --> CON\n",
    "  CFG --> LCFG\n",
    "  LCFG --> LGR\n",
    "  LGR --> CON\n",
    "```\n",
    "\n",
    "metadata\n",
    "language\n",
    "source\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Locate repository root by searching upwards for either 'src/research_agent_framework' or 'research_agent_framework' folder\n",
    "repo_cwd = Path.cwd().resolve()\n",
    "found_root = None\n",
    "for candidate in [repo_cwd] + list(repo_cwd.parents):\n",
    "    if (candidate / 'src' / 'research_agent_framework').exists() or (candidate / 'research_agent_framework').exists():\n",
    "        found_root = candidate.resolve()\n",
    "        break\n",
    "\n",
    "# If we found a root, prefer 'src' if present, otherwise use the root itself\n",
    "if found_root is not None:\n",
    "    src_candidate = (found_root / 'src') if (found_root / 'src' / 'research_agent_framework').exists() else found_root\n",
    "    src_path = str(src_candidate)\n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "        # Also set PYTHONPATH so spawned kernels may pick it up in some environments\n",
    "        os.environ['PYTHONPATH'] = os.environ.get('PYTHONPATH', '') or src_path\n",
    "\n",
    "# Now import project bootstrap and helpers safely\n",
    "from research_agent_framework.bootstrap import bootstrap\n",
    "from research_agent_framework.config import get_settings, get_console, get_logger\n",
    "\n",
    "# Initialize environment, console, and logging (idempotent)\n",
    "bootstrap()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-17-a39ad0fc"
   },
   "source": [
    "## Data Model Diagram (Key models & relationships)\n",
    "\n",
    "```mermaid\n",
    "classDiagram\n",
    "    direction LR\n",
    "    class SerpResult {\n",
    "        string id\n",
    "        string title\n",
    "        string snippet\n",
    "        string url\n",
    "        list citations\n",
    "        +from_raw(dict) SerpResult\n",
    "    }\n",
    "\n",
    "    class Scope {\n",
    "        string id\n",
    "        string question\n",
    "        list constraints\n",
    "        list clarifications\n",
    "    }\n",
    "\n",
    "    class ResearchTask {\n",
    "        string id\n",
    "        Scope scope\n",
    "        list steps\n",
    "        status\n",
    "    }\n",
    "\n",
    "    class EvalResult {\n",
    "        string task_id\n",
    "        bool success\n",
    "        float score\n",
    "        string feedback\n",
    "        dict details\n",
    "    }\n",
    "\n",
    "    class AgentContext {\n",
    "        settings\n",
    "        console\n",
    "        logger\n",
    "        llm_client\n",
    "        search_adapter\n",
    "    }\n",
    "\n",
    "    SerpResult --|> ResearchTask : evidence\n",
    "    Scope \"1\" o-- \"0..*\" ResearchTask : generates\n",
    "    ResearchTask \"1\" o-- \"0..*\" EvalResult : evaluated_by\n",
    "    AgentContext \"1\" -- \"*\" ResearchTask : used_by\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-18-538e213d"
   },
   "source": [
    "### Why this setup (results of the design)\n",
    "\n",
    "- **Env overrides work**: `LOGGING__LEVEL`, `LOGGING__FMT`, `LOGGING__BACKEND` populate real fields; the `logger` property reflects them at access time.\n",
    "- **Single ownership via properties**: `settings.console` and `settings.logger` are the shared instances used everywhere.\n",
    "- **Helpers remain simple**: `get_console()` / `get_logger()` just delegate to those shared instances when you prefer function calls.\n",
    "- **Robust bootstrap**: `bootstrap()` installs rich tracebacks, ensures a Console, and wires Loguru → Console idempotently.\n",
    "- **Notebook consistency**: Cells use property access (e.g., `settings.console`) for clarity; helpers are equivalent if preferred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-19-76df2e20"
   },
   "source": [
    "## Env vars: required and optional (4.1)\n",
    "\n",
    "Key environment variables used by the framework (recommended defaults shown):\n",
    "\n",
    "| Variable | Required? | Default | Description |\n",
    "|---|---:|---|---|\n",
    "| `SERPAPI_API_KEY` | Optional | — | API key for SerpAPI; if missing, notebook defaults to `Mock` adapter |\n",
    "| `TAVILY_API_KEY` | Optional | — | API key for Tavily adapter; if missing, notebook defaults to `Mock` adapter |\n",
    "| `LOGGING__LEVEL` | Optional | `INFO` | Logging verbosity |\n",
    "| `LOGGING__FMT` | Optional | project default | Logging format string |\n",
    "| `MODEL_NAME` | Optional | `mock-model` | LLM model to use when not mocking |\n",
    "| `MODEL_TEMPERATURE` | Optional | `0.0` | Controls LLM sampling |\n",
    "| `ENABLE_TRACING` | Optional | `False` | Enable tracing hooks |\n",
    "\n",
    "This section lists recommended env vars, safe defaults, and guidance on toggling live providers vs mocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "#VSC-auto-20-b64e14a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME = mock-model\n",
      "MODEL_TEMPERATURE = 0.0\n",
      "LOGGING__LEVEL = INFO\n",
      "ENABLE_TRACING = False\n",
      "SERPAPI_API_KEY present: False\n",
      "TAVILY_API_KEY present: True\n"
     ]
    }
   ],
   "source": [
    "# Safe demo: display resolved settings and show defaults\n",
    "from research_agent_framework.config import get_settings\n",
    "\n",
    "s = get_settings(force_reload=True)\n",
    "print('MODEL_NAME =', s.model_name)\n",
    "print('MODEL_TEMPERATURE =', s.model_temperature)\n",
    "print('LOGGING__LEVEL =', s.logging.level)\n",
    "print('ENABLE_TRACING =', s.enable_tracing)\n",
    "\n",
    "# Display whether external adapter keys are present\n",
    "import os\n",
    "print('SERPAPI_API_KEY present:', bool(os.environ.get('SERPAPI_API_KEY')))\n",
    "print('TAVILY_API_KEY present:', bool(os.environ.get('TAVILY_API_KEY')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-21-79360f33"
   },
   "source": [
    "### Safe defaults and fallback behavior (4.2)\n",
    "\n",
    "This cell demonstrates how the notebook and framework behave when external API keys are not provided. By default the notebook uses deterministic `Mock` adapters and `MockLLM` to keep examples reproducible and low-cost.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- If `SERPAPI_API_KEY` or `TAVILY_API_KEY` are missing, the framework falls back to the `Mock` search adapter.\n",
    "- If `MODEL_NAME` is set to a real provider name, `llm_factory` will create a live client — otherwise the `MockLLM` is used.\n",
    "- Use `get_settings(force_reload=True)` after mutating `os.environ` to observe changes at runtime in an idempotent manner.\n",
    "\n",
    "The next code cell runs a safe demo that temporarily unsets adapter-related env vars, reloads settings, and prints which adapters/LLM the framework would use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-22-3e00aa0f"
   },
   "source": [
    "### Switchboard helper: centralize mock/live toggles (4.3)\n",
    "\n",
    "This small utility centralizes environment-driven toggles used by the notebook and examples. Use the helper to make notebook cells short and declarative — change the environment in one place and the helper will consistently report whether the framework will use mocks or live providers.\n",
    "\n",
    "The code cell below demonstrates toggling `FORCE_USE_MOCK` and observing the resolved behavior for search adapters and the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "#VSC-auto-23-428e0b6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Baseline: <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_search</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_llm</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Baseline: \u001b[33muse_mock_search\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33muse_mock_llm\u001b[0m=\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">After <span style=\"color: #808000; text-decoration-color: #808000\">FORCE_USE_MOCK</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_search</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_llm</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "After \u001b[33mFORCE_USE_MOCK\u001b[0m=\u001b[1;36m1\u001b[0m: \u001b[33muse_mock_search\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33muse_mock_llm\u001b[0m=\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">After restore: <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_search</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">use_mock_llm</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "After restore: \u001b[33muse_mock_search\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33muse_mock_llm\u001b[0m=\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Switchboard demo cell: toggle FORCE_USE_MOCK and show effective choices\n",
    "import os\n",
    "from research_agent_framework.helpers.switchboard import use_mock_search, use_mock_llm\n",
    "from research_agent_framework.config import get_console, get_settings\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "# Baseline\n",
    "s = get_settings(force_reload=True)\n",
    "console.print(f\"Baseline: use_mock_search={use_mock_search(s)}, use_mock_llm={use_mock_llm(s)}\")\n",
    "\n",
    "# Force use of mocks\n",
    "os.environ['FORCE_USE_MOCK'] = '1'\n",
    "s_forced = get_settings(force_reload=True)\n",
    "console.print(f\"After FORCE_USE_MOCK=1: use_mock_search={use_mock_search(s_forced)}, use_mock_llm={use_mock_llm(s_forced)}\")\n",
    "\n",
    "# Clean up\n",
    "os.environ.pop('FORCE_USE_MOCK', None)\n",
    "s_restored = get_settings(force_reload=True)\n",
    "console.print(f\"After restore: use_mock_search={use_mock_search(s_restored)}, use_mock_llm={use_mock_llm(s_restored)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-24-1e674c40"
   },
   "source": [
    "### Central switchboard (6.0) - single place to toggle mocks vs live providers\n",
    "\n",
    "This small, editable cell is the recommended place to toggle the environment for the entire notebook when you want to run the examples against live providers. By default the notebook is mock-first (safe and deterministic).\n",
    "\n",
    "Change `FORCE_USE_MOCK` below or set provider-specific keys (`SERPAPI_API_KEY`, `TAVILY_API_KEY`, `MODEL_NAME`) to run with live services. Use `get_settings(force_reload=True)` after editing to apply changes in subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "#VSC-auto-25-65d5782c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central switchboard applied. Current: FORCE_USE_MOCK= 1 MODEL_NAME= mock-model\n"
     ]
    }
   ],
   "source": [
    "# Central switchboard: edit this cell to toggle mock vs live globally for the notebook\n",
    "# Options:\n",
    "#  - Set FORCE_USE_MOCK=1 to force all mocks\n",
    "#  - Unset FORCE_USE_MOCK and set provider keys (SERPAPI_API_KEY/TAVILY_API_KEY/MODEL_NAME) to use live providers\n",
    "import os\n",
    "# Example: force mocks for all demo cells (safe default)\n",
    "os.environ['FORCE_USE_MOCK'] = os.environ.get('FORCE_USE_MOCK', '1')\n",
    "# Example: to use live providers, uncomment and set real keys here (DO NOT commit secrets)\n",
    "# os.environ.pop('FORCE_USE_MOCK', None)\n",
    "# os.environ['SERPAPI_API_KEY'] = 'sk-...your-key...'\n",
    "# os.environ['TAVILY_API_KEY'] = 'tk-...your-key...'\n",
    "# os.environ['MODEL_NAME'] = 'openai-gpt-4'\n",
    "\n",
    "# Apply settings reload so later cells observe the new environment\n",
    "from research_agent_framework.config import get_settings\n",
    "s = get_settings(force_reload=True)\n",
    "print('Central switchboard applied. Current: FORCE_USE_MOCK=', os.environ.get('FORCE_USE_MOCK'), 'MODEL_NAME=', s.model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "#VSC-auto-26-ac8b7bf9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-27-05920a32"
   },
   "source": [
    "## 7.0 User Clarification and Scoping Demo\n",
    "\n",
    "This section demonstrates how the research agent iteratively refines the user's request using deterministic (mock) responses. The workflow ensures that the agent only proceeds to research after sufficient clarification, mirroring the logic in `research_agent_scope.py` and the corresponding tests.\n",
    "\n",
    "- **7.2 Iterative refinement:** The agent asks clarifying questions until enough information is provided.\n",
    "- **7.3 Scope state capture:** The agent validates and stores the scope state for downstream research.\n",
    "\n",
    "Cells below show the clarification loop and state validation, using mock adapters for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "#VSC-auto-28-b0459334"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 17:32:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:32:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">988</span> INFO HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                        <a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 17:32:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m17:32:37\u001b[0m,\u001b[1;36m988\u001b[0m INFO HTTP Request: \u001b[1;33mPOST\u001b[0m                        \u001b]8;id=954982;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=945192;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1 - Agent: Could you clarify what you mean by 'best'? Are you looking for coffee shops with the highest ratings, best atmosphere, specialty coffee, or something else? Also, do you have a specific neighborhood or area in San Francisco in mind, or should I consider the entire city?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 17:32:39] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:32:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270</span> INFO HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                        <a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 17:32:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m17:32:39\u001b[0m,\u001b[1;36m270\u001b[0m INFO HTTP Request: \u001b[1;33mPOST\u001b[0m                        \u001b]8;id=571588;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=55845;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 2 - Agent: Could you clarify what you mean by 'not paid'? Are you looking for coffee shops that offer free coffee, or do you mean places where you don't need to pay to enter (such as no cover charge or minimum purchase)?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 17:32:40] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:32:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">289</span> INFO HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                        <a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 17:32:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m17:32:40\u001b[0m,\u001b[1;36m289\u001b[0m INFO HTTP Request: \u001b[1;33mPOST\u001b[0m                        \u001b]8;id=492214;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=892477;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 17:32:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:32:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">089</span> INFO HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                        <a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 17:32:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m17:32:42\u001b[0m,\u001b[1;36m089\u001b[0m INFO HTTP Request: \u001b[1;33mPOST\u001b[0m                        \u001b]8;id=614038;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=461458;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 3 - Agent: Thank you for providing the necessary details. You are looking for the highest-rated coffee shops in the SOMA neighborhood of San Francisco that are open right now, do not have a cover charge, and are not paid-entry. I will now begin researching and compiling a list that matches your criteria.\n",
      "Agent is ready to start research or has sufficient info.\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Iterative refinement using deterministic responses (with max turns)\n",
    "from deep_research_from_scratch.research_agent_scope import scope_research, AgentInputState\n",
    "from deep_research_from_scratch.state_scope import AgentState\n",
    "from langchain_core.messages import HumanMessage, AnyMessage\n",
    "from typing import cast\n",
    "\n",
    "# Simulate a user request that needs clarification\n",
    "user_messages = [HumanMessage(content=\"Find the best coffee shops in SF.\")]\n",
    "input_state = AgentInputState(messages=cast(list[AnyMessage], user_messages))\n",
    "\n",
    "max_turns = 3\n",
    "turn = 0\n",
    "while turn < max_turns:\n",
    "    result = scope_research.invoke(input_state)\n",
    "    clarify_msg = result[\"messages\"][-1].content\n",
    "    print(f\"Turn {turn+1} - Agent: {clarify_msg}\")\n",
    "    # Simulate user providing more detail after each clarification\n",
    "    if \"clarify\" in clarify_msg.lower() or \"more detail\" in clarify_msg.lower():\n",
    "        if turn == 0:\n",
    "            user_messages.append(HumanMessage(content=\"I want places open now and not paid.\"))\n",
    "        elif turn == 1:\n",
    "            user_messages.append(HumanMessage(content=\"No cover charge, open now, highest ratings in SOMA.\"))\n",
    "        input_state = AgentInputState(messages=cast(list[AnyMessage], user_messages))\n",
    "        turn += 1\n",
    "    else:\n",
    "        print(\"Agent is ready to start research or has sufficient info.\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"Max turns ({max_turns}) reached. Please provide more specific details to proceed.\")\n",
    "    print(\"Conversation so far:\")\n",
    "    for msg in user_messages:\n",
    "        print(\"User:\", msg.content)\n",
    "    print(\"Last agent message:\", clarify_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "#VSC-auto-29-93d3e9fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:42.117 | INFO     | research_agent_framework.logging:info:92 - Starting scoping clarification loop</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">for user request.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:42.117 | INFO     | research_agent_framework.logging:info:92 - Starting scoping clarification loop\u001b[0m\n",
       "\u001b[1;35mfor user request.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:42.117330-0700 INFO Starting scoping clarification loop for user request.\n"
     ]
    }
   ],
   "source": [
    "# Logging: scoping clarification loop\n",
    "logger.info(\"Starting scoping clarification loop for user request.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-30-9a35b434"
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "This cell demonstrates how the agent uses deterministic logic to clarify ambiguous user requests. The agent asks for more details if needed, and only proceeds when the scope is sufficiently defined. This mirrors the logic in `research_agent_scope.py` and is validated by tests in `test_research_agent.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-31-b8c6235c"
   },
   "source": [
    "### 7.3 Capture scope state object and validation\n",
    "\n",
    "This cell demonstrates how the agent captures the scope state object after clarification and validates its structure, ensuring downstream research steps are well-defined and reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "#VSC-auto-32-0089063f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 17:32:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:32:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">879</span> INFO HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                        <a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 17:32:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m17:32:43\u001b[0m,\u001b[1;36m879\u001b[0m INFO HTTP Request: \u001b[1;33mPOST\u001b[0m                        \u001b]8;id=914048;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=425745;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/13/25 17:32:45] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:32:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">649</span> INFO HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                        <a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1025</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/13/25 17:32:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m13\u001b[0m \u001b[1;92m17:32:45\u001b[0m,\u001b[1;36m649\u001b[0m INFO HTTP Request: \u001b[1;33mPOST\u001b[0m                        \u001b]8;id=476052;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=700999;file://d:\\repos\\tpai_deep_research_from_scratch\\.venv\\Lib\\site-packages\\httpx\\_client.py#1025\u001b\\\u001b[2m1025\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Research brief:</span>                                                                                                    \n",
       "\n",
       "I want to find the highest-rated coffee shops in the SOMA neighborhood of San Francisco that are open right now (as\n",
       "of Saturday, September 13, 2025), do not have a cover charge or paid entry, and are accessible to the public.      \n",
       "Please focus on user ratings and reviews to determine quality. Only include places that meet all these criteria.   \n",
       "For any other aspects such as price range, menu offerings, or ambiance, treat them as open considerations since I  \n",
       "have not specified preferences. Prioritize linking directly to official websites or reputable review platforms     \n",
       "(such as Google Maps, Yelp, or the coffee shop's own site) for verification of hours and ratings.                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mResearch brief:\u001b[0m                                                                                                    \n",
       "\n",
       "I want to find the highest-rated coffee shops in the SOMA neighborhood of San Francisco that are open right now (as\n",
       "of Saturday, September 13, 2025), do not have a cover charge or paid entry, and are accessible to the public.      \n",
       "Please focus on user ratings and reviews to determine quality. Only include places that meet all these criteria.   \n",
       "For any other aspects such as price range, menu offerings, or ambiance, treat them as open considerations since I  \n",
       "have not specified preferences. Prioritize linking directly to official websites or reputable review platforms     \n",
       "(such as Google Maps, Yelp, or the coffee shop's own site) for verification of hours and ratings.                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7.3 Capture scope state object and validate\n",
    "from deep_research_from_scratch.research_agent_scope import scope_research, AgentInputState\n",
    "from deep_research_from_scratch.state_scope import AgentState\n",
    "from langchain_core.messages import HumanMessage, AnyMessage\n",
    "from assertpy import assert_that\n",
    "from typing import cast\n",
    "from research_agent_framework.config import get_console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "# Simulate clarified user request\n",
    "user_messages = [\n",
    "    HumanMessage(content=\"Find the best coffee shops in SF.\"),\n",
    "    HumanMessage(content=\"I want places open now and not paid.\"),\n",
    "    HumanMessage(content=\"No cover charge, open now, highest ratings in SOMA.\")\n",
    "]\n",
    "input_state = AgentInputState(messages=cast(list[AnyMessage], user_messages))\n",
    "result = scope_research.invoke(input_state)\n",
    "\n",
    "# Validate scope state object\n",
    "assert_that(result).contains_key(\"research_brief\")\n",
    "assert_that(result[\"research_brief\"]).is_not_empty()\n",
    "console.print(Markdown(f\"**Research brief:**\\n\\n{result['research_brief']}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "#VSC-auto-33-12b3c4a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.666 | INFO     | research_agent_framework.logging:info:92 - Validating scope state object after</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">clarification.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.666 | INFO     | research_agent_framework.logging:info:92 - Validating scope state object after\u001b[0m\n",
       "\u001b[1;35mclarification.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.666896-0700 INFO Validating scope state object after clarification.\n"
     ]
    }
   ],
   "source": [
    "# Logging: scope state validation\n",
    "logger.info(\"Validating scope state object after clarification.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-34-836bac7c"
   },
   "source": [
    "## 9.1 Supervisor Policy Demo: Deterministic Multi-Agent Coordination\n",
    "\n",
    "This section demonstrates how the supervisor agent orchestrates multiple research agents using a deterministic policy. The workflow ensures reproducibility and mirrors the logic in `multi_agent_supervisor.py` and the corresponding tests.\n",
    "\n",
    "- **Supervisor Policy:** Coordinates agent actions, assigns tasks, and validates outcomes.\n",
    "- **Deterministic Steps:** Uses mock adapters and fixed agent responses for educational clarity.\n",
    "\n",
    "Cells below show the supervisor's decision-making process and agent coordination, with output rendered using Rich's Markdown for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "#VSC-auto-35-8c732b61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A1 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Find top-rated coffee shops in SF.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A1 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Find top-rated coffee shops in SF.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A2 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Check which shops are open now.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A2 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Check which shops are open now.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A3 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Filter for no cover charge in SOMA.                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A3 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Filter for no cover charge in SOMA.                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9.1 Supervisor Policy Demo: Deterministic Multi-Agent Coordination\n",
    "from deep_research_from_scratch.multi_agent_supervisor import Supervisor, AgentTask, DeterministicPolicy\n",
    "from deep_research_from_scratch.state_scope import AgentState\n",
    "from research_agent_framework.config import get_console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "# Define mock agent tasks\n",
    "agent_tasks = [\n",
    "    AgentTask(agent_id=\"A1\", description=\"Find top-rated coffee shops in SF.\"),\n",
    "    AgentTask(agent_id=\"A2\", description=\"Check which shops are open now.\"),\n",
    "    AgentTask(agent_id=\"A3\", description=\"Filter for no cover charge in SOMA.\")\n",
    "]\n",
    "\n",
    "# Use deterministic supervisor policy for reproducibility\n",
    "policy = DeterministicPolicy()\n",
    "supervisor = Supervisor(policy=policy)\n",
    "\n",
    "# Run coordination workflow\n",
    "results = supervisor.coordinate(agent_tasks)\n",
    "\n",
    "# Validate and display results\n",
    "for result in results:\n",
    "    assert hasattr(result, \"agent_id\")\n",
    "    assert hasattr(result, \"outcome\")\n",
    "    console.print(Markdown(f\"**Agent {result.agent_id} outcome:**\\n\\n{result.outcome}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "#VSC-auto-36-c66052d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.689 | INFO     | research_agent_framework.logging:info:92 - Supervisor policy demo: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">coordinating agent tasks.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.689 | INFO     | research_agent_framework.logging:info:92 - Supervisor policy demo: \u001b[0m\n",
       "\u001b[1;35mcoordinating agent tasks.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.689372-0700 INFO Supervisor policy demo: coordinating agent tasks.\n"
     ]
    }
   ],
   "source": [
    "# Logging: supervisor policy demo\n",
    "logger.info(\"Supervisor policy demo: coordinating agent tasks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-37-dfd5f1d1"
   },
   "source": [
    "## 9.2 Logging Agent Messages and State Transitions\n",
    "\n",
    "This section demonstrates how the supervisor and agents log their messages and state transitions during coordination. Logging is essential for debugging, monitoring, and educational clarity.\n",
    "\n",
    "- **Structured Logging:** Each agent logs its actions and state changes.\n",
    "- **State Transition Tracking:** Supervisor logs before and after coordination steps.\n",
    "\n",
    "Cells below show how logging is integrated into the multi-agent workflow, with output rendered using Rich for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "#VSC-auto-38-9cd78468"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.702 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Starting coordination</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.702 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Starting coordination\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.702106-0700 INFO Supervisor: Starting coordination\n",
      "2025-09-13T17:32:45.702106-0700 INFO Supervisor: Starting coordination\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.704 | INFO     | research_agent_framework.logging:info:92 - Agent A1 starting: Find top-rated </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.704 | INFO     | research_agent_framework.logging:info:92 - Agent A1 starting: Find top-rated \u001b[0m\n",
       "\u001b[1;35mcoffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.704490-0700 INFO Agent A1 starting: Find top-rated coffee shops in SF.\n",
      "2025-09-13T17:32:45.704490-0700 INFO Agent A1 starting: Find top-rated coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.707 | INFO     | research_agent_framework.logging:info:92 - Agent A1 finished: Completed: Find </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">top-rated coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.707 | INFO     | research_agent_framework.logging:info:92 - Agent A1 finished: Completed: Find \u001b[0m\n",
       "\u001b[1;35mtop-rated coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.707306-0700 INFO Agent A1 finished: Completed: Find top-rated coffee shops in SF.\n",
      "2025-09-13T17:32:45.707306-0700 INFO Agent A1 finished: Completed: Find top-rated coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.709 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Agent A1 outcome: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Completed: Find top-rated coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.709 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Agent A1 outcome: \u001b[0m\n",
       "\u001b[1;35mCompleted: Find top-rated coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.709471-0700 INFO Supervisor: Agent A1 outcome: Completed: Find top-rated coffee shops in SF.\n",
      "2025-09-13T17:32:45.709471-0700 INFO Supervisor: Agent A1 outcome: Completed: Find top-rated coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.711 | INFO     | research_agent_framework.logging:info:92 - Agent A2 starting: Check which </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">shops are open now.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.711 | INFO     | research_agent_framework.logging:info:92 - Agent A2 starting: Check which \u001b[0m\n",
       "\u001b[1;35mshops are open now.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.711797-0700 INFO Agent A2 starting: Check which shops are open now.\n",
      "2025-09-13T17:32:45.711797-0700 INFO Agent A2 starting: Check which shops are open now.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.714 | INFO     | research_agent_framework.logging:info:92 - Agent A2 finished: Completed: Check</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">which shops are open now.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.714 | INFO     | research_agent_framework.logging:info:92 - Agent A2 finished: Completed: Check\u001b[0m\n",
       "\u001b[1;35mwhich shops are open now.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.714160-0700 INFO Agent A2 finished: Completed: Check which shops are open now.\n",
      "2025-09-13T17:32:45.714160-0700 INFO Agent A2 finished: Completed: Check which shops are open now.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.716 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Agent A2 outcome: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Completed: Check which shops are open now.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.716 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Agent A2 outcome: \u001b[0m\n",
       "\u001b[1;35mCompleted: Check which shops are open now.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.716694-0700 INFO Supervisor: Agent A2 outcome: Completed: Check which shops are open now.\n",
      "2025-09-13T17:32:45.716694-0700 INFO Supervisor: Agent A2 outcome: Completed: Check which shops are open now.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.719 | INFO     | research_agent_framework.logging:info:92 - Agent A3 starting: Filter for no </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">cover charge in SOMA.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.719 | INFO     | research_agent_framework.logging:info:92 - Agent A3 starting: Filter for no \u001b[0m\n",
       "\u001b[1;35mcover charge in SOMA.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.719093-0700 INFO Agent A3 starting: Filter for no cover charge in SOMA.\n",
      "2025-09-13T17:32:45.719093-0700 INFO Agent A3 starting: Filter for no cover charge in SOMA.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.721 | INFO     | research_agent_framework.logging:info:92 - Agent A3 finished: Completed: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Filter for no cover charge in SOMA.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.721 | INFO     | research_agent_framework.logging:info:92 - Agent A3 finished: Completed: \u001b[0m\n",
       "\u001b[1;35mFilter for no cover charge in SOMA.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.721434-0700 INFO Agent A3 finished: Completed: Filter for no cover charge in SOMA.\n",
      "2025-09-13T17:32:45.721434-0700 INFO Agent A3 finished: Completed: Filter for no cover charge in SOMA.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.723 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Agent A3 outcome: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Completed: Filter for no cover charge in SOMA.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.723 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Agent A3 outcome: \u001b[0m\n",
       "\u001b[1;35mCompleted: Filter for no cover charge in SOMA.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.723788-0700 INFO Supervisor: Agent A3 outcome: Completed: Filter for no cover charge in SOMA.\n",
      "2025-09-13T17:32:45.723788-0700 INFO Supervisor: Agent A3 outcome: Completed: Filter for no cover charge in SOMA.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.725 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Coordination complete</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.725 | INFO     | research_agent_framework.logging:info:92 - Supervisor: Coordination complete\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.725742-0700 INFO Supervisor: Coordination complete\n",
      "2025-09-13T17:32:45.725742-0700 INFO Supervisor: Coordination complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A1 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Find top-rated coffee shops in SF.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A1 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Find top-rated coffee shops in SF.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A2 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Check which shops are open now.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A2 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Check which shops are open now.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agent A3 outcome:</span>                                                                                                  \n",
       "\n",
       "Completed: Filter for no cover charge in SOMA.                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAgent A3 outcome:\u001b[0m                                                                                                  \n",
       "\n",
       "Completed: Filter for no cover charge in SOMA.                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9.2 Logging Agent Messages and State Transitions (with logger injection demo)\n",
    "from deep_research_from_scratch.multi_agent_supervisor import Supervisor, AgentTask, DeterministicPolicy, LoggingSupervisor, LoggingAgentTask\n",
    "from research_agent_framework.config import get_console, get_logger\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = get_console()\n",
    "logger = get_logger()\n",
    "\n",
    "# Inject logger into agent tasks and supervisor for reproducible logging\n",
    "agent_tasks = [\n",
    "    LoggingAgentTask(agent_id=\"A1\", description=\"Find top-rated coffee shops in SF.\", logger=logger),\n",
    "    LoggingAgentTask(agent_id=\"A2\", description=\"Check which shops are open now.\", logger=logger),\n",
    "    LoggingAgentTask(agent_id=\"A3\", description=\"Filter for no cover charge in SOMA.\", logger=logger)\n",
    "]\n",
    "supervisor = LoggingSupervisor(logger=logger)\n",
    "results = supervisor.coordinate(agent_tasks)\n",
    "\n",
    "for result in results:\n",
    "    console.print(Markdown(f\"**Agent {result.agent_id} outcome:**\\n\\n{result.outcome}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "#VSC-auto-39-4325c65e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.739 | INFO     | research_agent_framework.logging:info:92 - Logging agent messages and state </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">transitions during coordination.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.739 | INFO     | research_agent_framework.logging:info:92 - Logging agent messages and state \u001b[0m\n",
       "\u001b[1;35mtransitions during coordination.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.739919-0700 INFO Logging agent messages and state transitions during coordination.\n",
      "2025-09-13T17:32:45.739919-0700 INFO Logging agent messages and state transitions during coordination.\n",
      "2025-09-13T17:32:45.739919-0700 INFO Logging agent messages and state transitions during coordination.\n"
     ]
    }
   ],
   "source": [
    "# Logging: agent state transitions\n",
    "logger.info(\"Logging agent messages and state transitions during coordination.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-40-c0f7f12a"
   },
   "source": [
    "## 10.0 Research Compression and Synthesis\n",
    "\n",
    "This section demonstrates how to compress and synthesize research findings using deterministic logic (MockLLM) and structured outputs. The workflow mirrors the agent's compression node and aligns with tests in `test_supervisor_policy_deterministic.py` and `test_end_to_end_flow.py`.\n",
    "\n",
    "- **10.1 Compression strategy:** Uses a Jinja2 template and MockLLM to compress findings.\n",
    "- **10.2 Synthesis:** Produces structured objects for downstream reporting.\n",
    "- **10.3 Validation:** Validates outputs and displays with rich output.\n",
    "\n",
    "Cells below show the compression logic, synthesis, and output validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "#VSC-auto-41-68b4ccae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Compressed Research Summary:</span>                                                                                       \n",
       "\n",
       "mock response for:                                                                                                 \n",
       "\n",
       "\"\"\" Compress the following research findings and notes into a concise, comprehensive summary suitable for reporting\n",
       "and further synthesis.                                                                                             \n",
       "\n",
       "Guidelines:                                                                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Do NOT lose any details, facts, names, numbers, or specific findings                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Do NOT filter out information that seems relevant to the research topic                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Organize the information in a cleaner format but keep all the substance                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Include ALL sources and citations found during research                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Remember this research was conducted to answer the specific question above                                      \n",
       "\n",
       "Today's date is 2025-09-13.                                                                                        \n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.                                                       \n",
       "\n",
       "\n",
       "Please compress and synthesize the above findings into a single, well-structured summary. \"\"\"                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mCompressed Research Summary:\u001b[0m                                                                                       \n",
       "\n",
       "mock response for:                                                                                                 \n",
       "\n",
       "\"\"\" Compress the following research findings and notes into a concise, comprehensive summary suitable for reporting\n",
       "and further synthesis.                                                                                             \n",
       "\n",
       "Guidelines:                                                                                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0mDo NOT lose any details, facts, names, numbers, or specific findings                                            \n",
       "\u001b[1;33m • \u001b[0mDo NOT filter out information that seems relevant to the research topic                                         \n",
       "\u001b[1;33m • \u001b[0mOrganize the information in a cleaner format but keep all the substance                                         \n",
       "\u001b[1;33m • \u001b[0mInclude ALL sources and citations found during research                                                         \n",
       "\u001b[1;33m • \u001b[0mRemember this research was conducted to answer the specific question above                                      \n",
       "\n",
       "Today's date is 2025-09-13.                                                                                        \n",
       "\n",
       "\n",
       "\n",
       "\u001b[1;33m • \u001b[0mBlue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.                                            \n",
       "\u001b[1;33m • \u001b[0mSightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.                                         \n",
       "\u001b[1;33m • \u001b[0mVerve Coffee: 4.5 stars, open now, SOMA, no cover charge.                                                       \n",
       "\n",
       "\n",
       "Please compress and synthesize the above findings into a single, well-structured summary. \"\"\"                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10.1 Compression strategy with MockLLM\n",
    "from research_agent_framework.llm.client import MockLLM, LLMConfig\n",
    "from research_agent_framework.prompts import renderer\n",
    "from research_agent_framework.config import get_console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = get_console()\n",
    "mock_config = LLMConfig(api_key=\"test\", model=\"mock-model\")\n",
    "mock_llm = MockLLM(mock_config)\n",
    "\n",
    "# Example research brief and notes\n",
    "research_brief = 'Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.'\n",
    "notes = [\n",
    "    'Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.',\n",
    "    'Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.',\n",
    "    'Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.'\n",
    "]\n",
    "\n",
    "# Render compression prompt using Jinja2 template\n",
    "from datetime import date\n",
    "compression_prompt = renderer.render_template('compress_research.j2', {\n",
    "    'date': date.today().isoformat(),\n",
    "    'research_brief': research_brief,\n",
    "    'notes': notes\n",
    "})\n",
    "\n",
    "# Use MockLLM to compress findings\n",
    "import asyncio\n",
    "summary = asyncio.run(mock_llm.generate(compression_prompt))\n",
    "console.print(Markdown(f'**Compressed Research Summary:**\\n\\n{summary}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "id": "#VSC-auto-42-b0529475"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.763 | INFO     | research_agent_framework.logging:info:92 - Compressing and synthesizing </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">research findings.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.763 | INFO     | research_agent_framework.logging:info:92 - Compressing and synthesizing \u001b[0m\n",
       "\u001b[1;35mresearch findings.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.763402-0700 INFO Compressing and synthesizing research findings.\n",
      "2025-09-13T17:32:45.763402-0700 INFO Compressing and synthesizing research findings.\n",
      "2025-09-13T17:32:45.763402-0700 INFO Compressing and synthesizing research findings.\n"
     ]
    }
   ],
   "source": [
    "# Logging: compression and synthesis\n",
    "logger.info(\"Compressing and synthesizing research findings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-43-dd117d13"
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "This cell demonstrates how the agent compresses research findings using a Jinja2 template and MockLLM for deterministic output. The summary is rendered with rich Markdown for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "id": "#VSC-auto-44-75b410e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">EvalResult:</span>                                                                                                        \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "task_id='synth-001' success=True score=0.95 feedback='mock response for: \\n\\n\"\"\"\\nCompress the following research  \n",
       "findings and notes into a concise, comprehensive summary suitable for reporting and further                        \n",
       "synthesis.\\n\\nGuidelines:\\n- Do NOT lose any details, facts, names, numbers, or specific findings\\n- Do NOT filter \n",
       "out information that seems relevant to the research topic\\n- Organize the information in a cleaner format but keep \n",
       "all the substance\\n- Include ALL sources and citations found during research\\n- Remember this research was         \n",
       "conducted to answer the specific question above\\n\\nToday's date is 2025-09-13.\\n\\n\\nFind the best coffee shops in  \n",
       "SF with no cover charge, open now, highest ratings in SOMA.\\n&lt;/Research Brief&gt;\\n\\n\\n\\n- Blue Bottle Coffee: 4.7    \n",
       "stars, open now, free WiFi, no cover charge.\\n\\n- Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover  \n",
       "charge.\\n\\n- Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.\\n\\n\\n\\nPlease compress and synthesize the   \n",
       "above findings into a single, well-structured summary.\\n\"\"\"' details={'notes': 'Blue Bottle Coffee: 4.7 stars, open\n",
       "now, free WiFi, no cover charge.\\nSightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.\\nVerve   \n",
       "Coffee: 4.5 stars, open now, SOMA, no cover charge.'}                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mEvalResult:\u001b[0m                                                                                                        \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "task_id='synth-001' success=True score=0.95 feedback='mock response for: \\n\\n\"\"\"\\nCompress the following research  \n",
       "findings and notes into a concise, comprehensive summary suitable for reporting and further                        \n",
       "synthesis.\\n\\nGuidelines:\\n- Do NOT lose any details, facts, names, numbers, or specific findings\\n- Do NOT filter \n",
       "out information that seems relevant to the research topic\\n- Organize the information in a cleaner format but keep \n",
       "all the substance\\n- Include ALL sources and citations found during research\\n- Remember this research was         \n",
       "conducted to answer the specific question above\\n\\nToday's date is 2025-09-13.\\n\\n\\nFind the best coffee shops in  \n",
       "SF with no cover charge, open now, highest ratings in SOMA.\\n</Research Brief>\\n\\n\\n\\n- Blue Bottle Coffee: 4.7    \n",
       "stars, open now, free WiFi, no cover charge.\\n\\n- Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover  \n",
       "charge.\\n\\n- Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.\\n\\n\\n\\nPlease compress and synthesize the   \n",
       "above findings into a single, well-structured summary.\\n\"\"\"' details={'notes': 'Blue Bottle Coffee: 4.7 stars, open\n",
       "now, free WiFi, no cover charge.\\nSightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.\\nVerve   \n",
       "Coffee: 4.5 stars, open now, SOMA, no cover charge.'}                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10.2 Synthesize findings into structured objects\n",
    "from research_agent_framework.models import EvalResult\n",
    "from assertpy import assert_that\n",
    "\n",
    "# Simulate synthesis: wrap summary into EvalResult\n",
    "eval_result = EvalResult(\n",
    "    task_id='synth-001',\n",
    "    success=True,\n",
    "    score=0.95,\n",
    "    feedback=str(summary),\n",
    "    details={'notes': '\\n'.join(notes)}\n",
    " )\n",
    "# Validate structured output\n",
    "assert_that(eval_result).is_instance_of(EvalResult)\n",
    "assert_that(eval_result.feedback).contains('mock response for:')\n",
    "console.print(Markdown(f'**EvalResult:**\\n\\n{eval_result}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-45-4895b231"
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "This cell shows how compressed findings are synthesized into a structured EvalResult object, validated for type and content, and displayed with rich output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-46-1f9d9340"
   },
   "source": [
    "## 11.0 Final Report Generation\n",
    "\n",
    "This section demonstrates how to assemble the final research report, render it with rich output, and provide a downloadable artifact. The workflow uses deterministic logic and aligns with renderer and output tests.\n",
    "\n",
    "- **11.1 Assemble report sections and metadata**\n",
    "- **11.2 Verify formatting against renderer tests**\n",
    "- **11.3 Provide downloadable artifact (markdown export)\n",
    "\n",
    "Cells below show the report assembly, rendering, and export logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "id": "#VSC-auto-47-3061990b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Final Research Report:</span>                                                                                             \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                              <span style=\"font-weight: bold\">Final Research Report</span>                                              ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\n",
       "                                                  <span style=\"font-weight: bold; text-decoration: underline\">Research Brief</span>                                                   \n",
       "\n",
       "Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.                          \n",
       "\n",
       "\n",
       "                                                     <span style=\"font-weight: bold; text-decoration: underline\">Findings</span>                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.                                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "Today's date is 2025-09-13.                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mFinal Research Report:\u001b[0m                                                                                             \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                              \u001b[1mFinal Research Report\u001b[0m                                              ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\n",
       "                                                  \u001b[1;4mResearch Brief\u001b[0m                                                   \n",
       "\n",
       "Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.                          \n",
       "\n",
       "\n",
       "                                                     \u001b[1;4mFindings\u001b[0m                                                      \n",
       "\n",
       "\u001b[1;33m • \u001b[0mBlue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.                                            \n",
       "\u001b[1;33m • \u001b[0mSightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.                                         \n",
       "\u001b[1;33m • \u001b[0mVerve Coffee: 4.5 stars, open now, SOMA, no cover charge.                                                       \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "Today's date is 2025-09-13.                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.1 Assemble report sections and metadata\n",
    "from research_agent_framework.prompts import renderer\n",
    "from research_agent_framework.llm.client import MockLLM, LLMConfig\n",
    "from research_agent_framework.config import get_console\n",
    "from rich.markdown import Markdown\n",
    "from datetime import date\n",
    "\n",
    "console = get_console()\n",
    "mock_config = LLMConfig(api_key=\"test\", model=\"mock-model\")\n",
    "mock_llm = MockLLM(mock_config)\n",
    "\n",
    "# Example: assemble report sections\n",
    "report_metadata = {\n",
    "    'date': date.today().isoformat(),\n",
    "    'research_brief': 'Find the best coffee shops in SF with no cover charge, open now, highest ratings in SOMA.',\n",
    "    'findings': [\n",
    "        'Blue Bottle Coffee: 4.7 stars, open now, free WiFi, no cover charge.',\n",
    "        'Sightglass Coffee: 4.6 stars, open now, SOMA location, no cover charge.',\n",
    "        'Verve Coffee: 4.5 stars, open now, SOMA, no cover charge.'\n",
    "    ],\n",
    "    'sources': []\n",
    "}\n",
    "\n",
    "# Render final report using Jinja2 template\n",
    "final_report_prompt = renderer.render_template('final_report_generation_prompt.j2', report_metadata)\n",
    "\n",
    "# Sanitize prompt: remove any angle-bracket instruction tokens that may have leaked in\n",
    "import re\n",
    "sanitized_prompt = re.sub(r'<[^>]+>', '', final_report_prompt)\n",
    "# Collapse repeated blank lines for cleanliness\n",
    "sanitized_prompt = re.sub(r'\\n{3,}', '\\n\\n', sanitized_prompt).strip()\n",
    "\n",
    "# Strict Markdown lint compliance:\n",
    "# 1. Ensure exactly one blank line before and after each heading\n",
    "# 2. Ensure only a single trailing newline\n",
    "lines = sanitized_prompt.splitlines()\n",
    "output_lines = []\n",
    "for i, line in enumerate(lines):\n",
    "    if re.match(r'^#+ ', line):\n",
    "        # Add blank line before heading if not already present\n",
    "        if output_lines and output_lines[-1].strip() != '':\n",
    "            output_lines.append('')\n",
    "        output_lines.append(line)\n",
    "        # Add blank line after heading if next line is not blank or end of file\n",
    "        if i+1 < len(lines) and lines[i+1].strip() != '':\n",
    "            output_lines.append('')\n",
    "    else:\n",
    "        output_lines.append(line)\n",
    "# Remove leading/trailing blank lines\n",
    "while output_lines and output_lines[0].strip() == '':\n",
    "    output_lines.pop(0)\n",
    "while output_lines and output_lines[-1].strip() == '':\n",
    "    output_lines.pop()\n",
    "final_report = '\\n'.join(output_lines) + '\\n'\n",
    "\n",
    "console.print(Markdown(f'**Final Research Report:**\\n\\n{final_report}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "id": "#VSC-auto-48-03c722b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Report formatting validated against renderer tests.</span>                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mReport formatting validated against renderer tests.\u001b[0m                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.2 Verify formatting against renderer tests\n",
    "from assertpy import assert_that\n",
    "\n",
    "# Validate that the final report contains expected structure\n",
    "assert_that(final_report).contains('# Final Research Report')\n",
    "assert_that(final_report).contains('Findings')\n",
    "console.print(Markdown(f'**Report formatting validated against renderer tests.**'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "id": "#VSC-auto-49-d08770df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Final report saved as d:\\repos\\tpai_deep_research_from_scratch\\notebooks\\final_research_report.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✅ Final report saved as d:\\repos\\tpai_deep_research_from_scratch\\notebooks\\final_research_report.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.3 Provide downloadable artifact (markdown export)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Save the final report as a markdown file in the same folder as this notebook.\n",
    "# Prefer the helper_path.parent (set earlier when loading nb_bootstrap), otherwise fall back to cwd.\n",
    "try:\n",
    "    notebook_dir = Path(helper_path).parent if 'helper_path' in globals() else None\n",
    "except Exception:\n",
    "    notebook_dir = None\n",
    "if notebook_dir is None or not notebook_dir.exists():\n",
    "    notebook_dir = Path.cwd()\n",
    "output_path = notebook_dir / 'final_research_report.md'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(final_report)\n",
    "\n",
    "console.print(f'[bold green]✅ Final report saved as {output_path!s}[/bold green]')\n",
    "\n",
    "# Test: ensure the saved file contains the actual report, not the prompt\n",
    "with open(output_path, 'r', encoding='utf-8') as f:\n",
    "    saved_content = f.read()\n",
    "assert saved_content.startswith('# Final Research Report\\n'), \"Report does not start with expected header!\"\n",
    "assert '\\n## Findings\\n' in saved_content, \"Report does not contain a findings section!\"\n",
    "assert saved_content.endswith('\\n'), \"Report does not end with a single newline!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-50-d7e34f81"
   },
   "source": [
    "## 12.0 Structured Logging and LangSmith Tracing\n",
    "\n",
    "This section demonstrates how to enable LangSmith tracing and visualize traces for the research workflow. Tracing is optional and controlled by the `ENABLE_TRACING` environment variable or settings. When enabled, traces are sent to LangSmith for inspection and debugging. This is useful for understanding agent reasoning, tool calls, and workflow execution.\n",
    "\n",
    "- **12.1 Structured logs** are already integrated throughout the code and notebook (see previous sections).\n",
    "- **12.2 LangSmith tracing hooks** are enabled below if tracing is turned on.\n",
    "- **12.3 Minimal trace visualization**: If tracing is enabled, a link to the LangSmith UI is displayed for the current run. Otherwise, a message explains how to enable tracing.\n",
    "\n",
    "**Note:** You must have a valid LangSmith API key and project configured in your environment for traces to be sent. See [LangSmith documentation](https://docs.langchain.com/docs/langsmith) for setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "id": "#VSC-auto-51-10910097"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ℹ️ LangSmith tracing is DISABLED. Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ENABLE_TRACING</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> and configure your LangSmith API key to enable.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mℹ️ LangSmith tracing is DISABLED. Set \u001b[0m\u001b[1;36mENABLE_TRACING\u001b[0m\u001b[1;36m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m and configure your LangSmith API key to enable.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.866 | INFO     | research_agent_framework.logging:info:92 - LangSmith tracing is disabled.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.866 | INFO     | research_agent_framework.logging:info:92 - LangSmith tracing is disabled.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.866270-0700 INFO LangSmith tracing is disabled.\n",
      "2025-09-13T17:32:45.866270-0700 INFO LangSmith tracing is disabled.\n",
      "2025-09-13T17:32:45.866270-0700 INFO LangSmith tracing is disabled.\n"
     ]
    }
   ],
   "source": [
    "# 12.2 Enable LangSmith tracing if configured\n",
    "import os\n",
    "from research_agent_framework.config import get_settings, get_logger, get_console\n",
    "\n",
    "settings = get_settings()\n",
    "logger = get_logger()\n",
    "console = get_console()\n",
    "\n",
    "# Check if tracing is enabled (via env or settings)\n",
    "enable_tracing = bool(os.environ.get(\"ENABLE_TRACING\", str(settings.enable_tracing)).lower() in (\"1\", \"true\", \"yes\"))\n",
    "\n",
    "if enable_tracing:\n",
    "    try:\n",
    "        from langsmith import traceable, LangSmithTracer\n",
    "        # Optionally set up LangSmithTracer with env/config\n",
    "        tracer = LangSmithTracer()\n",
    "        console.print(\"[bold green]✅ LangSmith tracing is ENABLED. Traces will be sent to your LangSmith project.[/bold green]\")\n",
    "        logger.info(\"LangSmith tracing enabled.\")\n",
    "    except ImportError:\n",
    "        console.print(\"[bold yellow]⚠️ LangSmith tracing requested but 'langsmith' package is not installed. Please install it to enable tracing.[/bold yellow]\")\n",
    "        logger.warning(\"LangSmith tracing requested but package not installed.\")\n",
    "else:\n",
    "    console.print(\"[bold cyan]ℹ️ LangSmith tracing is DISABLED. Set ENABLE_TRACING=1 and configure your LangSmith API key to enable.[/bold cyan]\")\n",
    "    logger.info(\"LangSmith tracing is disabled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "#VSC-auto-52-321f6a31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ℹ️ Tracing is off. To view traces, set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ENABLE_TRACING</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> and rerun this section.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mℹ️ Tracing is off. To view traces, set \u001b[0m\u001b[1;36mENABLE_TRACING\u001b[0m\u001b[1;36m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m and rerun this section.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 12.3 Minimal trace visualization or LangSmith UI link\n",
    "if enable_tracing:\n",
    "    # If LangSmith tracing is enabled, show a link to the LangSmith project UI\n",
    "    langsmith_project = os.environ.get(\"LANGCHAIN_PROJECT\", \"default\")\n",
    "    langsmith_url = f\"https://smith.langchain.com/o/projects/{langsmith_project}\"\n",
    "    console.print(f\"[bold blue]🔗 View your traces in LangSmith: [link={langsmith_url}]{langsmith_url}[/link][/bold blue]\")\n",
    "else:\n",
    "    console.print(\"[bold cyan]ℹ️ Tracing is off. To view traces, set ENABLE_TRACING=1 and rerun this section.[/bold cyan]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-53-3e8402ee"
   },
   "source": [
    "# 13.0 Comparing Prompts and LLM Settings Side-by-Side\n",
    "\n",
    "This section demonstrates how prompt wording and LLM settings (such as temperature and max_tokens) affect outputs. We use deterministic mock LLMs for educational clarity, and log all steps generously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-54-a70a8057"
   },
   "source": [
    "## 13.1 Varying Prompts: Deterministic Output Comparison\n",
    "\n",
    "We compare how different prompt phrasings affect the output of a mock LLM. All outputs and steps are logged for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "#VSC-auto-55-75cd03e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.892 | INFO     | research_agent_framework.logging:info:92 - Comparing prompt: Summarize the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.892 | INFO     | research_agent_framework.logging:info:92 - Comparing prompt: Summarize the \u001b[0m\n",
       "\u001b[1;35mbest coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.892527-0700 INFO Comparing prompt: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.892527-0700 INFO Comparing prompt: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.896 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summarize the best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.896 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: \u001b[0m\n",
       "\u001b[1;35mSummarize the best coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.896966-0700 INFO Output: mock response for: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.896966-0700 INFO Output: mock response for: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.902 | INFO     | research_agent_framework.logging:info:92 - Comparing prompt: List top-rated </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">coffee shops in San Francisco.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.902 | INFO     | research_agent_framework.logging:info:92 - Comparing prompt: List top-rated \u001b[0m\n",
       "\u001b[1;35mcoffee shops in San Francisco.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.902515-0700 INFO Comparing prompt: List top-rated coffee shops in San Francisco.\n",
      "2025-09-13T17:32:45.902515-0700 INFO Comparing prompt: List top-rated coffee shops in San Francisco.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.906 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: List </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">top-rated coffee shops in San Francisco.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.906 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: List \u001b[0m\n",
       "\u001b[1;35mtop-rated coffee shops in San Francisco.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.906298-0700 INFO Output: mock response for: List top-rated coffee shops in San Francisco.\n",
      "2025-09-13T17:32:45.906298-0700 INFO Output: mock response for: List top-rated coffee shops in San Francisco.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.909 | INFO     | research_agent_framework.logging:info:92 - Comparing prompt: What are the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">highest rated places for coffee in SF?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.909 | INFO     | research_agent_framework.logging:info:92 - Comparing prompt: What are the \u001b[0m\n",
       "\u001b[1;35mhighest rated places for coffee in SF?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.909707-0700 INFO Comparing prompt: What are the highest rated places for coffee in SF?\n",
      "2025-09-13T17:32:45.909707-0700 INFO Comparing prompt: What are the highest rated places for coffee in SF?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.912 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: What are</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">the highest rated places for coffee in SF?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.912 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: What are\u001b[0m\n",
       "\u001b[1;35mthe highest rated places for coffee in SF?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.912839-0700 INFO Output: mock response for: What are the highest rated places for coffee in SF?\n",
      "2025-09-13T17:32:45.912839-0700 INFO Output: mock response for: What are the highest rated places for coffee in SF?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.915 | INFO     | research_agent_framework.logging:info:92 - Comparing prompt: Find coffee shops</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">open now in SOMA, SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.915 | INFO     | research_agent_framework.logging:info:92 - Comparing prompt: Find coffee shops\u001b[0m\n",
       "\u001b[1;35mopen now in SOMA, SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.915680-0700 INFO Comparing prompt: Find coffee shops open now in SOMA, SF.\n",
      "2025-09-13T17:32:45.915680-0700 INFO Comparing prompt: Find coffee shops open now in SOMA, SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.918 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: Find </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">coffee shops open now in SOMA, SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.918 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: Find \u001b[0m\n",
       "\u001b[1;35mcoffee shops open now in SOMA, SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.918737-0700 INFO Output: mock response for: Find coffee shops open now in SOMA, SF.\n",
      "2025-09-13T17:32:45.918737-0700 INFO Output: mock response for: Find coffee shops open now in SOMA, SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.922 | INFO     | research_agent_framework.logging:info:92 - Prompt: Summarize the best coffee </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">shops in SF.</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Output: mock response for: Summarize the best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.922 | INFO     | research_agent_framework.logging:info:92 - Prompt: Summarize the best coffee \u001b[0m\n",
       "\u001b[1;35mshops in SF.\u001b[0m\n",
       "\u001b[1;35mOutput: mock response for: Summarize the best coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.922429-0700 INFO Prompt: Summarize the best coffee shops in SF.\n",
      "Output: mock response for: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.922429-0700 INFO Prompt: Summarize the best coffee shops in SF.\n",
      "Output: mock response for: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Prompt:</span> Summarize the best coffee shops in SF.\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Output:</span> mock response for: Summarize the best coffee shops in SF.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPrompt:\u001b[0m Summarize the best coffee shops in SF.\n",
       "\u001b[32mOutput:\u001b[0m mock response for: Summarize the best coffee shops in SF.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.926 | INFO     | research_agent_framework.logging:info:92 - Prompt: List top-rated coffee shops</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">in San Francisco.</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Output: mock response for: List top-rated coffee shops in San Francisco.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.926 | INFO     | research_agent_framework.logging:info:92 - Prompt: List top-rated coffee shops\u001b[0m\n",
       "\u001b[1;35min San Francisco.\u001b[0m\n",
       "\u001b[1;35mOutput: mock response for: List top-rated coffee shops in San Francisco.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.926774-0700 INFO Prompt: List top-rated coffee shops in San Francisco.\n",
      "Output: mock response for: List top-rated coffee shops in San Francisco.\n",
      "2025-09-13T17:32:45.926774-0700 INFO Prompt: List top-rated coffee shops in San Francisco.\n",
      "Output: mock response for: List top-rated coffee shops in San Francisco.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Prompt:</span> List top-rated coffee shops in San Francisco.\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Output:</span> mock response for: List top-rated coffee shops in San Francisco.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPrompt:\u001b[0m List top-rated coffee shops in San Francisco.\n",
       "\u001b[32mOutput:\u001b[0m mock response for: List top-rated coffee shops in San Francisco.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.931 | INFO     | research_agent_framework.logging:info:92 - Prompt: What are the highest rated </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">places for coffee in SF?</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Output: mock response for: What are the highest rated places for coffee in SF?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.931 | INFO     | research_agent_framework.logging:info:92 - Prompt: What are the highest rated \u001b[0m\n",
       "\u001b[1;35mplaces for coffee in SF?\u001b[0m\n",
       "\u001b[1;35mOutput: mock response for: What are the highest rated places for coffee in SF?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.931368-0700 INFO Prompt: What are the highest rated places for coffee in SF?\n",
      "Output: mock response for: What are the highest rated places for coffee in SF?\n",
      "2025-09-13T17:32:45.931368-0700 INFO Prompt: What are the highest rated places for coffee in SF?\n",
      "Output: mock response for: What are the highest rated places for coffee in SF?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Prompt:</span> What are the highest rated places for coffee in SF?\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Output:</span> mock response for: What are the highest rated places for coffee in SF?\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPrompt:\u001b[0m What are the highest rated places for coffee in SF?\n",
       "\u001b[32mOutput:\u001b[0m mock response for: What are the highest rated places for coffee in SF?\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.935 | INFO     | research_agent_framework.logging:info:92 - Prompt: Find coffee shops open now </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">in SOMA, SF.</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Output: mock response for: Find coffee shops open now in SOMA, SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.935 | INFO     | research_agent_framework.logging:info:92 - Prompt: Find coffee shops open now \u001b[0m\n",
       "\u001b[1;35min SOMA, SF.\u001b[0m\n",
       "\u001b[1;35mOutput: mock response for: Find coffee shops open now in SOMA, SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.935849-0700 INFO Prompt: Find coffee shops open now in SOMA, SF.\n",
      "Output: mock response for: Find coffee shops open now in SOMA, SF.\n",
      "2025-09-13T17:32:45.935849-0700 INFO Prompt: Find coffee shops open now in SOMA, SF.\n",
      "Output: mock response for: Find coffee shops open now in SOMA, SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Prompt:</span> Find coffee shops open now in SOMA, SF.\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Output:</span> mock response for: Find coffee shops open now in SOMA, SF.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPrompt:\u001b[0m Find coffee shops open now in SOMA, SF.\n",
       "\u001b[32mOutput:\u001b[0m mock response for: Find coffee shops open now in SOMA, SF.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare several prompt phrasings using the mock LLM and log outputs\n",
    "from research_agent_framework.llm.client import LLMConfig\n",
    "from research_agent_framework.llm.compare import compare_prompts\n",
    "from research_agent_framework.config import get_logger, get_console\n",
    "import asyncio\n",
    "\n",
    "logger = get_logger()\n",
    "console = get_console()\n",
    "\n",
    "prompts = [\n",
    "    \"Summarize the best coffee shops in SF.\",\n",
    "    \"List top-rated coffee shops in San Francisco.\",\n",
    "    \"What are the highest rated places for coffee in SF?\",\n",
    "    \"Find coffee shops open now in SOMA, SF.\",\n",
    "]\n",
    "config = LLMConfig(api_key=\"test\", model=\"mock-model\")\n",
    "\n",
    "results = asyncio.run(compare_prompts(prompts, config))\n",
    "\n",
    "for prompt, output in results.items():\n",
    "    logger.info(f\"Prompt: {prompt}\\nOutput: {output}\")\n",
    "    console.print(f\"[bold]Prompt:[/bold] {prompt}\\n[green]Output:[/green] {output}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-56-c3352f54"
   },
   "source": [
    "## 13.2 Demonstrating Temperature and Max Tokens Effects\n",
    "\n",
    "We show how changing the temperature and max_tokens settings affects the output, using the mock LLM for deterministic demonstration. All results are logged and displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "id": "#VSC-auto-57-8ba93361"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.953 | INFO     | research_agent_framework.logging:info:92 - Comparing settings: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model=mock-model, temp=0.0, max_tokens=32</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.953 | INFO     | research_agent_framework.logging:info:92 - Comparing settings: \u001b[0m\n",
       "\u001b[1;35mmodel=mock-model, temp=0.0, max_tokens=32\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.953329-0700 INFO Comparing settings: model=mock-model, temp=0.0, max_tokens=32\n",
      "2025-09-13T17:32:45.953329-0700 INFO Comparing settings: model=mock-model, temp=0.0, max_tokens=32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.956 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summarize the best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.956 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: \u001b[0m\n",
       "\u001b[1;35mSummarize the best coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.956659-0700 INFO Output: mock response for: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.956659-0700 INFO Output: mock response for: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.960 | INFO     | research_agent_framework.logging:info:92 - Comparing settings: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model=mock-model, temp=1.0, max_tokens=128</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.960 | INFO     | research_agent_framework.logging:info:92 - Comparing settings: \u001b[0m\n",
       "\u001b[1;35mmodel=mock-model, temp=1.0, max_tokens=128\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.960651-0700 INFO Comparing settings: model=mock-model, temp=1.0, max_tokens=128\n",
      "2025-09-13T17:32:45.960651-0700 INFO Comparing settings: model=mock-model, temp=1.0, max_tokens=128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.963 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summarize the best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.963 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: \u001b[0m\n",
       "\u001b[1;35mSummarize the best coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.963311-0700 INFO Output: mock response for: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.963311-0700 INFO Output: mock response for: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.966 | INFO     | research_agent_framework.logging:info:92 - Comparing settings: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">model=mock-model, temp=2.0, max_tokens=256</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.966 | INFO     | research_agent_framework.logging:info:92 - Comparing settings: \u001b[0m\n",
       "\u001b[1;35mmodel=mock-model, temp=2.0, max_tokens=256\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.966374-0700 INFO Comparing settings: model=mock-model, temp=2.0, max_tokens=256\n",
      "2025-09-13T17:32:45.966374-0700 INFO Comparing settings: model=mock-model, temp=2.0, max_tokens=256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.969 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Summarize the best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.969 | INFO     | research_agent_framework.logging:info:92 - Output: mock response for: \u001b[0m\n",
       "\u001b[1;35mSummarize the best coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.969358-0700 INFO Output: mock response for: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.969358-0700 INFO Output: mock response for: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.973 | INFO     | research_agent_framework.logging:info:92 - Settings: model=mock-model, </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">temp=0.0, max_tokens=32</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Output: mock response for: Summarize the best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.973 | INFO     | research_agent_framework.logging:info:92 - Settings: model=mock-model, \u001b[0m\n",
       "\u001b[1;35mtemp=0.0, max_tokens=32\u001b[0m\n",
       "\u001b[1;35mOutput: mock response for: Summarize the best coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.973309-0700 INFO Settings: model=mock-model, temp=0.0, max_tokens=32\n",
      "Output: mock response for: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.973309-0700 INFO Settings: model=mock-model, temp=0.0, max_tokens=32\n",
      "Output: mock response for: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Settings:</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080\">mock</span>-model, <span style=\"color: #808000; text-decoration-color: #808000\">temp</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Output:</span> mock response for: Summarize the best coffee shops in SF.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSettings:\u001b[0m \u001b[33mmodel\u001b[0m=\u001b[35mmock\u001b[0m-model, \u001b[33mtemp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33mmax_tokens\u001b[0m=\u001b[1;36m32\u001b[0m\n",
       "\u001b[32mOutput:\u001b[0m mock response for: Summarize the best coffee shops in SF.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.978 | INFO     | research_agent_framework.logging:info:92 - Settings: model=mock-model, </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">temp=1.0, max_tokens=128</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Output: mock response for: Summarize the best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.978 | INFO     | research_agent_framework.logging:info:92 - Settings: model=mock-model, \u001b[0m\n",
       "\u001b[1;35mtemp=1.0, max_tokens=128\u001b[0m\n",
       "\u001b[1;35mOutput: mock response for: Summarize the best coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.978118-0700 INFO Settings: model=mock-model, temp=1.0, max_tokens=128\n",
      "Output: mock response for: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.978118-0700 INFO Settings: model=mock-model, temp=1.0, max_tokens=128\n",
      "Output: mock response for: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Settings:</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080\">mock</span>-model, <span style=\"color: #808000; text-decoration-color: #808000\">temp</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Output:</span> mock response for: Summarize the best coffee shops in SF.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSettings:\u001b[0m \u001b[33mmodel\u001b[0m=\u001b[35mmock\u001b[0m-model, \u001b[33mtemp\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33mmax_tokens\u001b[0m=\u001b[1;36m128\u001b[0m\n",
       "\u001b[32mOutput:\u001b[0m mock response for: Summarize the best coffee shops in SF.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:45.982 | INFO     | research_agent_framework.logging:info:92 - Settings: model=mock-model, </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">temp=2.0, max_tokens=256</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Output: mock response for: Summarize the best coffee shops in SF.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:45.982 | INFO     | research_agent_framework.logging:info:92 - Settings: model=mock-model, \u001b[0m\n",
       "\u001b[1;35mtemp=2.0, max_tokens=256\u001b[0m\n",
       "\u001b[1;35mOutput: mock response for: Summarize the best coffee shops in SF.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:45.982635-0700 INFO Settings: model=mock-model, temp=2.0, max_tokens=256\n",
      "Output: mock response for: Summarize the best coffee shops in SF.\n",
      "2025-09-13T17:32:45.982635-0700 INFO Settings: model=mock-model, temp=2.0, max_tokens=256\n",
      "Output: mock response for: Summarize the best coffee shops in SF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Settings:</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080\">mock</span>-model, <span style=\"color: #808000; text-decoration-color: #808000\">temp</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Output:</span> mock response for: Summarize the best coffee shops in SF.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSettings:\u001b[0m \u001b[33mmodel\u001b[0m=\u001b[35mmock\u001b[0m-model, \u001b[33mtemp\u001b[0m=\u001b[1;36m2\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33mmax_tokens\u001b[0m=\u001b[1;36m256\u001b[0m\n",
       "\u001b[32mOutput:\u001b[0m mock response for: Summarize the best coffee shops in SF.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare settings: temperature and max_tokens\n",
    "from research_agent_framework.llm.compare import compare_settings\n",
    "\n",
    "prompt = \"Summarize the best coffee shops in SF.\"\n",
    "configs = [\n",
    "    LLMConfig(api_key=\"test\", model=\"mock-model\", temperature=0.0, max_tokens=32),\n",
    "    LLMConfig(api_key=\"test\", model=\"mock-model\", temperature=1.0, max_tokens=128),\n",
    "    LLMConfig(api_key=\"test\", model=\"mock-model\", temperature=2.0, max_tokens=256),\n",
    "]\n",
    "\n",
    "results = asyncio.run(compare_settings(prompt, configs))\n",
    "\n",
    "for label, output in results.items():\n",
    "    logger.info(f\"Settings: {label}\\nOutput: {output}\")\n",
    "    console.print(f\"[bold]Settings:[/bold] {label}\\n[green]Output:[/green] {output}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-58-713bea3f"
   },
   "source": [
    "## 13.3 Best Practices and Trade-Offs\n",
    "\n",
    "- **Prompt clarity matters:** Small changes in phrasing can affect LLM output quality and relevance.\n",
    "- **Temperature:** Lower values make output more deterministic; higher values increase creativity and variability.\n",
    "- **Max tokens:** Controls output length; set appropriately for your use case.\n",
    "- **Log everything:** Use structured logging to track prompt, settings, and outputs for reproducibility and debugging.\n",
    "- **Use mocks for education/testing:** Deterministic mock LLMs help you understand effects without provider variability.\n",
    "\n",
    "**Try varying prompts and settings above to see effects in real time!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-59-254cde51"
   },
   "source": [
    "# 14.0 MCP Server Initialization and Tool Discovery\n",
    "\n",
    "This section demonstrates initializing a minimal in-process MCP server, registering tools, listing and describing them, and explaining async usage patterns. All steps are logged for educational clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-60-90da5de8"
   },
   "source": [
    "## 14.1 Start a Simple In-Process MCP Stub\n",
    "\n",
    "We initialize the MCPStub, which acts as a minimal async message bus for tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "id": "#VSC-auto-61-21b719cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ MCPStub initialized. ToolRegistry ready.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✅ MCPStub initialized. ToolRegistry ready.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.000 | INFO     | research_agent_framework.logging:info:92 - MCPStub and ToolRegistry </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">initialized.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.000 | INFO     | research_agent_framework.logging:info:92 - MCPStub and ToolRegistry \u001b[0m\n",
       "\u001b[1;35minitialized.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.000533-0700 INFO MCPStub and ToolRegistry initialized.\n",
      "2025-09-13T17:32:46.000533-0700 INFO MCPStub and ToolRegistry initialized.\n",
      "2025-09-13T17:32:46.000533-0700 INFO MCPStub and ToolRegistry initialized.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MCPStub and ToolRegistry with logging\n",
    "from research_agent_framework.mcp.stub import MCPStub\n",
    "from research_agent_framework.mcp.tools import ToolRegistry\n",
    "from research_agent_framework.config import get_logger, get_console\n",
    "\n",
    "logger = get_logger()\n",
    "console = get_console()\n",
    "\n",
    "mcp = MCPStub()\n",
    "tool_registry = ToolRegistry(logger)\n",
    "console.print(\"[bold green]✅ MCPStub initialized. ToolRegistry ready.[/bold green]\")\n",
    "logger.info(\"MCPStub and ToolRegistry initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-62-ae588600"
   },
   "source": [
    "## 14.2 Register, Discover, and List Tools\n",
    "\n",
    "We register example tools, list them, and display their descriptions. All actions are logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "id": "#VSC-auto-63-69d10c4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.015 | INFO     | research_agent_framework.logging:info:92 - Registering tool: square</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.015 | INFO     | research_agent_framework.logging:info:92 - Registering tool: square\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.015165-0700 INFO Registering tool: square\n",
      "2025-09-13T17:32:46.015165-0700 INFO Registering tool: square\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.018 | INFO     | research_agent_framework.logging:info:92 - Registering tool: plus_ten</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.018 | INFO     | research_agent_framework.logging:info:92 - Registering tool: plus_ten\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.018157-0700 INFO Registering tool: plus_ten\n",
      "2025-09-13T17:32:46.018157-0700 INFO Registering tool: plus_ten\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.021 | INFO     | research_agent_framework.logging:info:92 - Listing 2 registered tools.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.021 | INFO     | research_agent_framework.logging:info:92 - Listing 2 registered tools.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.021585-0700 INFO Listing 2 registered tools.\n",
      "2025-09-13T17:32:46.021585-0700 INFO Listing 2 registered tools.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Registered tools:</span>\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'square'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'plus_ten'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mRegistered tools:\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[32m'square'\u001b[0m, \u001b[32m'plus_ten'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.027 | INFO     | research_agent_framework.logging:info:92 - Listing 2 registered tools.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.027 | INFO     | research_agent_framework.logging:info:92 - Listing 2 registered tools.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.027144-0700 INFO Listing 2 registered tools.\n",
      "2025-09-13T17:32:46.027144-0700 INFO Listing 2 registered tools.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.029 | INFO     | research_agent_framework.logging:info:92 - Registered tools: ['square', </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">'plus_ten']</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.029 | INFO     | research_agent_framework.logging:info:92 - Registered tools: ['square', \u001b[0m\n",
       "\u001b[1;35m'plus_ten']\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.029905-0700 INFO Registered tools: ['square', 'plus_ten']\n",
      "2025-09-13T17:32:46.029905-0700 INFO Registered tools: ['square', 'plus_ten']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.032 | INFO     | research_agent_framework.logging:info:92 - Tool: square - Returns x squared.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.032 | INFO     | research_agent_framework.logging:info:92 - Tool: square - Returns x squared.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.032873-0700 INFO Tool: square - Returns x squared.\n",
      "2025-09-13T17:32:46.032873-0700 INFO Tool: square - Returns x squared.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.036 | INFO     | research_agent_framework.logging:info:92 - Tool: plus_ten - Returns y plus 10.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.036 | INFO     | research_agent_framework.logging:info:92 - Tool: plus_ten - Returns y plus 10.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.036290-0700 INFO Tool: plus_ten - Returns y plus 10.\n",
      "2025-09-13T17:32:46.036290-0700 INFO Tool: plus_ten - Returns y plus 10.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">square:</span> Returns x squared.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1msquare:\u001b[0m Returns x squared.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.041 | INFO     | research_agent_framework.logging:info:92 - Tool square: Returns x squared.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.041 | INFO     | research_agent_framework.logging:info:92 - Tool square: Returns x squared.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.041072-0700 INFO Tool square: Returns x squared.\n",
      "2025-09-13T17:32:46.041072-0700 INFO Tool square: Returns x squared.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">plus_ten:</span> Returns y plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mplus_ten:\u001b[0m Returns y plus \u001b[1;36m10\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.045 | INFO     | research_agent_framework.logging:info:92 - Tool plus_ten: Returns y plus 10.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.045 | INFO     | research_agent_framework.logging:info:92 - Tool plus_ten: Returns y plus 10.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.045830-0700 INFO Tool plus_ten: Returns y plus 10.\n",
      "2025-09-13T17:32:46.045830-0700 INFO Tool plus_ten: Returns y plus 10.\n",
      "2025-09-13T17:32:46.045830-0700 INFO Tool plus_ten: Returns y plus 10.\n"
     ]
    }
   ],
   "source": [
    "# Register example tools and list them\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Returns x squared.\"\"\"\n",
    "    return x * x\n",
    "\n",
    "def plus_ten(y):\n",
    "    \"\"\"Returns y plus 10.\"\"\"\n",
    "    return y + 10\n",
    "\n",
    "tool_registry.register(\"square\", square)\n",
    "tool_registry.register(\"plus_ten\", plus_ten)\n",
    "\n",
    "console.print(\"[bold blue]Registered tools:[/bold blue]\", list(tool_registry.list_tools().keys()))\n",
    "logger.info(f\"Registered tools: {list(tool_registry.list_tools().keys())}\")\n",
    "\n",
    "desc = tool_registry.describe_tools()\n",
    "for name, doc in desc.items():\n",
    "    console.print(f\"[bold]{name}:[/bold] {doc}\")\n",
    "    logger.info(f\"Tool {name}: {doc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-64-2ebbfd06"
   },
   "source": [
    "## 14.3 Async Usage Patterns Explained\n",
    "\n",
    "The MCPStub and ToolRegistry support async tool calls and concurrent handling. This enables scalable, non-blocking workflows in agent systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "id": "#VSC-auto-65-195699ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.059 | INFO     | research_agent_framework.logging:info:92 - Listing 2 registered tools.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.059 | INFO     | research_agent_framework.logging:info:92 - Listing 2 registered tools.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.059035-0700 INFO Listing 2 registered tools.\n",
      "2025-09-13T17:32:46.059035-0700 INFO Listing 2 registered tools.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Async square result:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mAsync square result:\u001b[0m \u001b[1;36m49\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.064 | INFO     | research_agent_framework.logging:info:92 - Async square result: 49</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.064 | INFO     | research_agent_framework.logging:info:92 - Async square result: 49\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.064672-0700 INFO Async square result: 49\n",
      "2025-09-13T17:32:46.064672-0700 INFO Async square result: 49\n",
      "2025-09-13T17:32:46.064672-0700 INFO Async square result: 49\n"
     ]
    }
   ],
   "source": [
    "# Example: Async tool call via MCPStub\n",
    "import asyncio\n",
    "\n",
    "async def handle_square(message):\n",
    "    result = tool_registry.list_tools()[\"square\"](message)\n",
    "    console.print(f\"[bold green]Async square result:[/bold green] {result}\")\n",
    "    logger.info(f\"Async square result: {result}\")\n",
    "\n",
    "mcp.register_handler(\"square\", handle_square)\n",
    "\n",
    "async def demo_async_call():\n",
    "    await mcp.publish(\"square\", 7)\n",
    "\n",
    "asyncio.run(demo_async_call())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-66-6bd77105"
   },
   "source": [
    "## Summary: MCP Server and Tool Discovery\n",
    "\n",
    "- MCPStub provides a minimal async message bus for agent workflows.\n",
    "- ToolRegistry enables tool registration, listing, and description with logging.\n",
    "- Async usage patterns allow scalable, non-blocking tool calls.\n",
    "- All steps are logged for reproducibility and debugging.\n",
    "\n",
    "**Try registering your own tools and publishing async messages to see the effects!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-67-2dc22a17"
   },
   "source": [
    "## 15.0 MCP Filesystem Operations and Error Handling\n",
    "\n",
    "\n",
    "This section demonstrates how to use the MCPFileTool to read local documentation files, handle errors safely, and use mock mode for deterministic educational runs. All actions are logged at appropriate levels for clarity and reproducibility.\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Read local files using the MCPFileTool\n",
    "\n",
    "- Handle file-not-found and other errors gracefully\n",
    "\n",
    "- Use mock mode for deterministic outputs in tests and demos\n",
    "\n",
    "- Observe structured logging at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "id": "#VSC-auto-68-c49018a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.081 | INFO     | research_agent_framework.logging:info:92 - MCPFileTool.read_file called with </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">path: ../docs/notes.md</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.081 | INFO     | research_agent_framework.logging:info:92 - MCPFileTool.read_file called with \u001b[0m\n",
       "\u001b[1;35mpath: ../docs/notes.md\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.081500-0700 INFO MCPFileTool.read_file called with path: ../docs/notes.md\n",
      "2025-09-13T17:32:46.081500-0700 INFO MCPFileTool.read_file called with path: ../docs/notes.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.085 | INFO     | research_agent_framework.logging:info:92 - Successfully read file: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">../docs/notes.md</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.085 | INFO     | research_agent_framework.logging:info:92 - Successfully read file: \u001b[0m\n",
       "\u001b[1;35m../docs/notes.md\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.085769-0700 INFO Successfully read file: ../docs/notes.md\n",
      "2025-09-13T17:32:46.085769-0700 INFO Successfully read file: ../docs/notes.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">File content:</span> # <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>\n",
       "\n",
       "## terms\n",
       "\n",
       "- Ported\n",
       "  \n",
       "## `1_scoping.ipynb`\n",
       "\n",
       "- forked project\n",
       "- fixed until running\n",
       "- f<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mFile content:\u001b[0m # \u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m28\u001b[0m\n",
       "\n",
       "## terms\n",
       "\n",
       "- Ported\n",
       "  \n",
       "## `1_scoping.ipynb`\n",
       "\n",
       "- forked project\n",
       "- fixed until running\n",
       "- f\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.092 | INFO     | research_agent_framework.logging:info:92 - Read file: ../docs/notes.md </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">(length=483)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.092 | INFO     | research_agent_framework.logging:info:92 - Read file: ../docs/notes.md \u001b[0m\n",
       "\u001b[1;35m(length=483)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.092204-0700 INFO Read file: ../docs/notes.md (length=483)\n",
      "2025-09-13T17:32:46.092204-0700 INFO Read file: ../docs/notes.md (length=483)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.096 | INFO     | research_agent_framework.logging:info:92 - MCPFileTool.read_file called with </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">path: ../docs/notes.md</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.096 | INFO     | research_agent_framework.logging:info:92 - MCPFileTool.read_file called with \u001b[0m\n",
       "\u001b[1;35mpath: ../docs/notes.md\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.096026-0700 INFO MCPFileTool.read_file called with path: ../docs/notes.md\n",
      "2025-09-13T17:32:46.096026-0700 INFO MCPFileTool.read_file called with path: ../docs/notes.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.099 | WARNING  | research_agent_framework.logging:warning:95 - [MOCK MODE] Returning </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">deterministic content.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.099 | WARNING  | research_agent_framework.logging:warning:95 - [MOCK MODE] Returning \u001b[0m\n",
       "\u001b[1;35mdeterministic content.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.099525-0700 WARNING [MOCK MODE] Returning deterministic content.\n",
      "2025-09-13T17:32:46.099525-0700 WARNING [MOCK MODE] Returning deterministic content.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">File content:</span> <span style=\"font-weight: bold\">[</span>MOCK CONTENT<span style=\"font-weight: bold\">]</span> File: notes.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mFile content:\u001b[0m \u001b[1m[\u001b[0mMOCK CONTENT\u001b[1m]\u001b[0m File: notes.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.104 | INFO     | research_agent_framework.logging:info:92 - Read file: ../docs/notes.md </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">(length=29)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.104 | INFO     | research_agent_framework.logging:info:92 - Read file: ../docs/notes.md \u001b[0m\n",
       "\u001b[1;35m(length=29)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.104055-0700 INFO Read file: ../docs/notes.md (length=29)\n",
      "2025-09-13T17:32:46.104055-0700 INFO Read file: ../docs/notes.md (length=29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[MOCK CONTENT] File: notes.md'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15.1 Read local docs via MCPFileTool\n",
    "from research_agent_framework.mcp.file_tools import MCPFileTool\n",
    "from research_agent_framework.config import get_logger, get_console\n",
    "\n",
    "logger = get_logger()\n",
    "console = get_console()\n",
    "\n",
    "# Use mock_mode=False for real file access, True for deterministic demo\n",
    "def read_doc_demo(path, mock_mode=False):\n",
    "    file_tool = MCPFileTool(logger, mock_mode=mock_mode)\n",
    "    content = file_tool.read_file(path)\n",
    "    if content is not None:\n",
    "        console.print(f\"[bold green]File content:[/bold green] {content[:100]}{'...' if len(content) > 100 else ''}\")\n",
    "        logger.info(f\"Read file: {path} (length={len(content)})\")\n",
    "    else:\n",
    "        console.print(f\"[bold red]File not found or error:[/bold red] {path}\")\n",
    "        logger.error(f\"Failed to read file: {path}\")\n",
    "    return content\n",
    "\n",
    "# Example: Try reading a real file (will fail if not present)\n",
    "read_doc_demo(\"../docs/notes.md\", mock_mode=False)\n",
    "\n",
    "# Example: Deterministic mock mode\n",
    "read_doc_demo(\"../docs/notes.md\", mock_mode=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-69-f5c8796c"
   },
   "source": [
    "### 15.2 Error Handling and Safe Patterns\n",
    "\n",
    "The MCPFileTool logs errors at the appropriate level and returns None for missing or unreadable files. Always check for None before using file content. Mock mode ensures deterministic outputs for tests and demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "id": "#VSC-auto-70-2ca21ead"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.121 | INFO     | research_agent_framework.logging:info:92 - MCPFileTool.read_file called with </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">path: /any/path/to/file.md</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.121 | INFO     | research_agent_framework.logging:info:92 - MCPFileTool.read_file called with \u001b[0m\n",
       "\u001b[1;35mpath: /any/path/to/file.md\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.121098-0700 INFO MCPFileTool.read_file called with path: /any/path/to/file.md\n",
      "2025-09-13T17:32:46.121098-0700 INFO MCPFileTool.read_file called with path: /any/path/to/file.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.126 | WARNING  | research_agent_framework.logging:warning:95 - [MOCK MODE] Returning </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">deterministic content.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.126 | WARNING  | research_agent_framework.logging:warning:95 - [MOCK MODE] Returning \u001b[0m\n",
       "\u001b[1;35mdeterministic content.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.126224-0700 WARNING [MOCK MODE] Returning deterministic content.\n",
      "2025-09-13T17:32:46.126224-0700 WARNING [MOCK MODE] Returning deterministic content.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">File content:</span> <span style=\"font-weight: bold\">[</span>MOCK CONTENT<span style=\"font-weight: bold\">]</span> File: file.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mFile content:\u001b[0m \u001b[1m[\u001b[0mMOCK CONTENT\u001b[1m]\u001b[0m File: file.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.131 | INFO     | research_agent_framework.logging:info:92 - Read file: /any/path/to/file.md </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">(length=28)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.131 | INFO     | research_agent_framework.logging:info:92 - Read file: /any/path/to/file.md \u001b[0m\n",
       "\u001b[1;35m(length=28)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.131807-0700 INFO Read file: /any/path/to/file.md (length=28)\n",
      "2025-09-13T17:32:46.131807-0700 INFO Read file: /any/path/to/file.md (length=28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Mock file content:</span> <span style=\"font-weight: bold\">[</span>MOCK CONTENT<span style=\"font-weight: bold\">]</span> File: file.md\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mMock file content:\u001b[0m \u001b[1m[\u001b[0mMOCK CONTENT\u001b[1m]\u001b[0m File: file.md\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.138 | INFO     | research_agent_framework.logging:info:92 - Mock file content: [MOCK CONTENT] </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">File: file.md</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.138 | INFO     | research_agent_framework.logging:info:92 - Mock file content: [MOCK CONTENT] \u001b[0m\n",
       "\u001b[1;35mFile: file.md\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.138701-0700 INFO Mock file content: [MOCK CONTENT] File: file.md\n",
      "2025-09-13T17:32:46.138701-0700 INFO Mock file content: [MOCK CONTENT] File: file.md\n",
      "2025-09-13T17:32:46.138701-0700 INFO Mock file content: [MOCK CONTENT] File: file.md\n"
     ]
    }
   ],
   "source": [
    "# 15.3 Mock fallback for deterministic runs\n",
    "# This cell demonstrates that mock_mode returns predictable content for any file path\n",
    "mock_content = read_doc_demo(\"/any/path/to/file.md\", mock_mode=True)\n",
    "console.print(f\"[bold yellow]Mock file content:[/bold yellow] {mock_content}\")\n",
    "logger.info(f\"Mock file content: {mock_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "id": "#VSC-auto-71-f03556b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Stylized log: [INFO] Operation succeeded</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mStylized log: [INFO] Operation succeeded\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">Stylized log: [WARNING] Check your input</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;33mStylized log: [WARNING] Check your input\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Stylized log: [ERROR] Operation failed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mStylized log: [ERROR] Operation failed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Stylized log: [INFO] Operation succeeded</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mStylized log: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[1;32mINFO\u001b[0m\u001b[1;32m]\u001b[0m\u001b[1;32m Operation succeeded\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">Stylized log: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; font-style: italic\">[</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">WARNING</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; font-style: italic\">]</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\"> Check your input</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;33mStylized log: \u001b[0m\u001b[1;3;33m[\u001b[0m\u001b[3;33mWARNING\u001b[0m\u001b[1;3;33m]\u001b[0m\u001b[3;33m Check your input\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Stylized log: [ERROR] Operation failed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mStylized log: \u001b[0m\u001b[1;31m[\u001b[0m\u001b[1;31mERROR\u001b[0m\u001b[1;31m]\u001b[0m\u001b[1;31m Operation failed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.169 | INFO     | research_agent_framework.logging:info:92 - [bold green]Structured log: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Operation succeeded[/bold green]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.169 | INFO     | research_agent_framework.logging:info:92 - [bold green]Structured log: \u001b[0m\n",
       "\u001b[1;35mOperation succeeded[/bold green]\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.169048-0700 INFO [bold green]Structured log: Operation succeeded[/bold green]\n",
      "2025-09-13T17:32:46.169048-0700 INFO [bold green]Structured log: Operation succeeded[/bold green]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.172 | WARNING  | research_agent_framework.logging:warning:95 - [italic yellow]Structured log: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Check your input[/italic yellow]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.172 | WARNING  | research_agent_framework.logging:warning:95 - [italic yellow]Structured log: \u001b[0m\n",
       "\u001b[1;35mCheck your input[/italic yellow]\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.172392-0700 WARNING [italic yellow]Structured log: Check your input[/italic yellow]\n",
      "2025-09-13T17:32:46.172392-0700 WARNING [italic yellow]Structured log: Check your input[/italic yellow]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.175 | ERROR    | research_agent_framework.logging:error:98 - [bold red]Structured log: </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Operation failed[/bold red]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.175 | ERROR    | research_agent_framework.logging:error:98 - [bold red]Structured log: \u001b[0m\n",
       "\u001b[1;35mOperation failed[/bold red]\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13T17:32:46.175726-0700 ERROR [bold red]Structured log: Operation failed[/bold red]\n",
      "2025-09-13T17:32:46.175726-0700 ERROR [bold red]Structured log: Operation failed[/bold red]\n",
      "2025-09-13T17:32:46.175726-0700 ERROR [bold red]Structured log: Operation failed[/bold red]\n"
     ]
    }
   ],
   "source": [
    "# 15.4 Stylized Logging: Color, Bold, Italic\n",
    "from rich.console import Console\n",
    "from rich.text import Text\n",
    "\n",
    "console = get_console()\n",
    "\n",
    "# Example: Stylized log message using rich\n",
    "console.print(Text(\"Stylized log: [INFO] Operation succeeded\", style=\"bold green\"))\n",
    "console.print(Text(\"Stylized log: [WARNING] Check your input\", style=\"italic yellow\"))\n",
    "console.print(Text(\"Stylized log: [ERROR] Operation failed\", style=\"bold red\"))\n",
    "\n",
    "# You can also use rich's markup directly\n",
    "console.print(\"[bold green]Stylized log: [INFO] Operation succeeded[/bold green]\")\n",
    "console.print(\"[italic yellow]Stylized log: [WARNING] Check your input[/italic yellow]\")\n",
    "console.print(\"[bold red]Stylized log: [ERROR] Operation failed[/bold red]\")\n",
    "\n",
    "# For structured logs, you can combine loguru/standard logging with rich output\n",
    "logger.info(\"[bold green]Structured log: Operation succeeded[/bold green]\")\n",
    "logger.warning(\"[italic yellow]Structured log: Check your input[/italic yellow]\")\n",
    "logger.error(\"[bold red]Structured log: Operation failed[/bold red]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "#VSC-auto-72-c21a4b69"
   },
   "source": [
    "### Logging Troubleshooting & Stylization Tips\n",
    "\n",
    "If log messages are not stylized (color, bold, italic), check the following:\n",
    "\n",
    "- **Rich Console**: Use `console.print()` with rich markup or `Text` objects for stylized output in notebook cells.\n",
    "- **Loguru/StdLogger**: By default, loguru and std logging output to stderr and do not support rich formatting. For stylized logs, print to the console in addition to logging.\n",
    "- **Custom Sink**: To route loguru logs to rich, add a custom sink using `logger.add(lambda msg: console.print(msg, style=\"bold green\"))`.\n",
    "- **Example**: See the next cell for a custom loguru-to-rich demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "#VSC-auto-73-1e7f496f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.189 | INFO     | __main__:&lt;module&gt;:11 - This is a stylized loguru INFO message (bold magenta)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.189 | INFO     | __main__:<module>:11 - This is a stylized loguru INFO message (bold magenta)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.191 | WARNING  | __main__:&lt;module&gt;:12 - This is a stylized loguru WARNING message (bold </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">magenta)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.191 | WARNING  | __main__:<module>:12 - This is a stylized loguru WARNING message (bold \u001b[0m\n",
       "\u001b[1;35mmagenta)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:46.193 | ERROR    | __main__:&lt;module&gt;:13 - This is a stylized loguru ERROR message (bold magenta)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:46.193 | ERROR    | __main__:<module>:13 - This is a stylized loguru ERROR message (bold magenta)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 15.5 Custom Loguru Sink for Rich Stylized Logging\n",
    "from loguru import logger as loguru_logger\n",
    "from rich.text import Text\n",
    "\n",
    "# Remove previous handlers to avoid duplicate logs\n",
    "loguru_logger.remove()\n",
    "\n",
    "# Add a custom sink that prints loguru messages to rich console with style\n",
    "loguru_logger.add(lambda msg: console.print(Text(msg, style=\"bold magenta\")), level=\"INFO\")\n",
    "\n",
    "loguru_logger.info(\"This is a stylized loguru INFO message (bold magenta)\")\n",
    "loguru_logger.warning(\"This is a stylized loguru WARNING message (bold magenta)\")\n",
    "loguru_logger.error(\"This is a stylized loguru ERROR message (bold magenta)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "id": "#VSC-auto-74-3b7021e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Rich console and traceback are now active! Stylized output will appear below.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mRich console and traceback are now active! Stylized output will appear below.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 15.6 Rich Traceback and Console Setup (Magic for Stylized Output)\n",
    "from rich import traceback\n",
    "from rich.console import Console\n",
    "\n",
    "# Install rich traceback for stylized error output in notebook\n",
    "traceback.install()\n",
    "\n",
    "# Ensure a fresh rich console instance for stylized printing\n",
    "console = Console()\n",
    "console.print(\"[bold green]Rich console and traceback are now active! Stylized output will appear below.[/bold green]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.0 Benchmark: Mock vs Simulated Live LLMs\n",
    "\n",
    "This conservative benchmark measures MockLLM latency (deterministic) and compares it with a simulated 'live' provider (async sleep).\n",
    "\n",
    "Guidelines:\n",
    "- Keep number of runs small by default to avoid long notebook execution (configurable).\n",
    "- Do NOT call external services; the simulated live provider uses `asyncio.sleep()` to emulate network latency.\n",
    "- Save results to the notebook folder as `benchmarks/llm_latency.json` for later inspection and CI artifact collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Throughput/variability results saved to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">d:\\repos\\tpai_deep_research_from_scratch\\notebooks\\benchmarks\\llm_throughput.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✅ Throughput/variability results saved to \u001b[0m\n",
       "\u001b[1;32md:\\repos\\tpai_deep_research_from_scratch\\notebooks\\benchmarks\\llm_throughput.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">MockLLM (default)</span> outputs: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for:</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Summarize the signal: a short deterministic test. '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mMockLLM \u001b[0m\u001b[1m(\u001b[0m\u001b[1mdefault\u001b[0m\u001b[1m)\u001b[0m outputs: \u001b[1m[\u001b[0m\u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response\u001b[0m\n",
       "\u001b[32mfor: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for: Summarize the signal: a short \u001b[0m\n",
       "\u001b[32mdeterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for:\u001b[0m\n",
       "\u001b[32mSummarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">MockLLM (default)</span> unique outputs: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">response for: Summarize the signal: a short deterministic test. '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mMockLLM \u001b[0m\u001b[1m(\u001b[0m\u001b[1mdefault\u001b[0m\u001b[1m)\u001b[0m unique outputs: \u001b[1m[\u001b[0m\u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock \u001b[0m\n",
       "\u001b[32mresponse for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for: Summarize the signal: a \u001b[0m\n",
       "\u001b[32mshort deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock \u001b[0m\n",
       "\u001b[32mresponse for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">MockLLM (default)</span> unique count: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mMockLLM \u001b[0m\u001b[1m(\u001b[0m\u001b[1mdefault\u001b[0m\u001b[1m)\u001b[0m unique count: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">MockLLM (high temp)</span> outputs: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">response for: Summarize the signal: a short deterministic test. '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mMockLLM \u001b[0m\u001b[1m(\u001b[0m\u001b[1mhigh temp\u001b[0m\u001b[1m)\u001b[0m outputs: \u001b[1m[\u001b[0m\u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock \u001b[0m\n",
       "\u001b[32mresponse for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for: Summarize the signal: a \u001b[0m\n",
       "\u001b[32mshort deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock \u001b[0m\n",
       "\u001b[32mresponse for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">MockLLM (high temp)</span> unique outputs: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'mock </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">response for: Summarize the signal: a short deterministic test. '</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mMockLLM \u001b[0m\u001b[1m(\u001b[0m\u001b[1mhigh temp\u001b[0m\u001b[1m)\u001b[0m unique outputs: \u001b[1m[\u001b[0m\u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock\u001b[0m\n",
       "\u001b[32mresponse for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for: Summarize the signal: a \u001b[0m\n",
       "\u001b[32mshort deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'mock \u001b[0m\n",
       "\u001b[32mresponse for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">MockLLM (high temp)</span> unique count: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mMockLLM \u001b[0m\u001b[1m(\u001b[0m\u001b[1mhigh temp\u001b[0m\u001b[1m)\u001b[0m unique count: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Simulated live</span> outputs: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 0'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 2'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 4'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSimulated live\u001b[0m outputs: \u001b[1m[\u001b[0m\u001b[32m'simulated live response 0'\u001b[0m, \u001b[32m'simulated live response 1'\u001b[0m, \u001b[32m'simulated live response 2'\u001b[0m, \n",
       "\u001b[32m'simulated live response 3'\u001b[0m, \u001b[32m'simulated live response 4'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Simulated live</span> unique outputs: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 0'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 1'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSimulated live\u001b[0m unique outputs: \u001b[1m[\u001b[0m\u001b[32m'simulated live response 0'\u001b[0m, \u001b[32m'simulated live response 2'\u001b[0m, \u001b[32m'simulated live response \u001b[0m\n",
       "\u001b[32m3'\u001b[0m, \u001b[32m'simulated live response 4'\u001b[0m, \u001b[32m'simulated live response 1'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Simulated live</span> unique count: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSimulated live\u001b[0m unique count: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MockLLM (default)'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'latencies'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0383999979239888</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.44640000123763457</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1899999988381751</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8473000052617863</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17839999782154337</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'mean_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5401000002166256</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'median_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.44640000123763457</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stdev_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.38886094022200324</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'outputs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 0]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 1]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 2]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 3]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 4]'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'unique_outputs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'all_outputs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 1]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 3]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 0]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 2]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 4]'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MockLLM (high temp)'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'latencies'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2647000001161359</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.15100000018719584</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0988000028883107</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.08369999704882503</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.07249999907799065</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'mean_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.13413999986369163</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'median_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0988000028883107</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stdev_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.07893473925318262</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'outputs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 0]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 1]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 2]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 3]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 4]'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'unique_outputs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'all_outputs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 1]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 3]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 0]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 2]'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'mock response for: Summarize the signal: a short deterministic test. [run 4]'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Simulated live'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'latencies'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">208.03199999500066</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201.1345999999321</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">214.1886000026716</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201.67450000008103</span>,\n",
       "            <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">205.348800001957</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'mean_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">206.07569999992847</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'median_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">205.348800001957</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stdev_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.337594738758764</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'outputs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 0'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 2'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 3'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 4'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'unique_outputs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'all_outputs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 0'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 2'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 3'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 4'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'simulated live response 1'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'MockLLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mdefault\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'latencies'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;36m1.0383999979239888\u001b[0m,\n",
       "            \u001b[1;36m0.44640000123763457\u001b[0m,\n",
       "            \u001b[1;36m0.1899999988381751\u001b[0m,\n",
       "            \u001b[1;36m0.8473000052617863\u001b[0m,\n",
       "            \u001b[1;36m0.17839999782154337\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'mean_ms'\u001b[0m: \u001b[1;36m0.5401000002166256\u001b[0m,\n",
       "        \u001b[32m'median_ms'\u001b[0m: \u001b[1;36m0.44640000123763457\u001b[0m,\n",
       "        \u001b[32m'stdev_ms'\u001b[0m: \u001b[1;36m0.38886094022200324\u001b[0m,\n",
       "        \u001b[32m'outputs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 0\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'unique_outputs'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "        \u001b[32m'all_outputs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 0\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'MockLLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mhigh temp\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'latencies'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;36m0.2647000001161359\u001b[0m,\n",
       "            \u001b[1;36m0.15100000018719584\u001b[0m,\n",
       "            \u001b[1;36m0.0988000028883107\u001b[0m,\n",
       "            \u001b[1;36m0.08369999704882503\u001b[0m,\n",
       "            \u001b[1;36m0.07249999907799065\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'mean_ms'\u001b[0m: \u001b[1;36m0.13413999986369163\u001b[0m,\n",
       "        \u001b[32m'median_ms'\u001b[0m: \u001b[1;36m0.0988000028883107\u001b[0m,\n",
       "        \u001b[32m'stdev_ms'\u001b[0m: \u001b[1;36m0.07893473925318262\u001b[0m,\n",
       "        \u001b[32m'outputs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 0\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'unique_outputs'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "        \u001b[32m'all_outputs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 0\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'mock response for: Summarize the signal: a short deterministic test. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mrun 4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'Simulated live'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'latencies'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1;36m208.03199999500066\u001b[0m,\n",
       "            \u001b[1;36m201.1345999999321\u001b[0m,\n",
       "            \u001b[1;36m214.1886000026716\u001b[0m,\n",
       "            \u001b[1;36m201.67450000008103\u001b[0m,\n",
       "            \u001b[1;36m205.348800001957\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'mean_ms'\u001b[0m: \u001b[1;36m206.07569999992847\u001b[0m,\n",
       "        \u001b[32m'median_ms'\u001b[0m: \u001b[1;36m205.348800001957\u001b[0m,\n",
       "        \u001b[32m'stdev_ms'\u001b[0m: \u001b[1;36m5.337594738758764\u001b[0m,\n",
       "        \u001b[32m'outputs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'simulated live response 0'\u001b[0m,\n",
       "            \u001b[32m'simulated live response 1'\u001b[0m,\n",
       "            \u001b[32m'simulated live response 2'\u001b[0m,\n",
       "            \u001b[32m'simulated live response 3'\u001b[0m,\n",
       "            \u001b[32m'simulated live response 4'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'unique_outputs'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "        \u001b[32m'all_outputs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'simulated live response 0'\u001b[0m,\n",
       "            \u001b[32m'simulated live response 2'\u001b[0m,\n",
       "            \u001b[32m'simulated live response 3'\u001b[0m,\n",
       "            \u001b[32m'simulated live response 4'\u001b[0m,\n",
       "            \u001b[32m'simulated live response 1'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 16.2 Compare throughput/variability under different settings\n",
    "import time\n",
    "import asyncio\n",
    "import json\n",
    "from statistics import mean, median, stdev\n",
    "from pathlib import Path\n",
    "\n",
    "n_runs = 5\n",
    "prompt = 'Summarize the signal: a short deterministic test.'\n",
    "configs = [\n",
    "    {'label': 'MockLLM (default)', 'config': {'api_key': 'test', 'model': 'mock-model', 'temperature': 0.0, 'max_tokens': 32}},\n",
    "    {'label': 'MockLLM (high temp)', 'config': {'api_key': 'test', 'model': 'mock-model', 'temperature': 2.0, 'max_tokens': 128}},\n",
    "    {'label': 'Simulated live', 'config': None},\n",
    "]\n",
    "results = {}\n",
    "for entry in configs:\n",
    "    label = entry['label']\n",
    "    config = entry['config']\n",
    "    latencies = []\n",
    "    outputs = []\n",
    "    for i in range(n_runs):\n",
    "        t0 = time.perf_counter()\n",
    "        if config:\n",
    "            from research_agent_framework.llm.client import MockLLM, LLMConfig\n",
    "            llm = MockLLM(LLMConfig(**config))\n",
    "            output = asyncio.run(llm.generate(f'{prompt} [run {i}]'))\n",
    "        else:\n",
    "            async def simulated_live_call(prompt, delay=0.2, run_idx=0):\n",
    "                await asyncio.sleep(delay)\n",
    "                return f'simulated live response {run_idx}'\n",
    "            output = asyncio.run(simulated_live_call(prompt, delay=0.2, run_idx=i))\n",
    "        t1 = time.perf_counter()\n",
    "        latencies.append((t1-t0)*1000.0)\n",
    "        outputs.append(str(output))\n",
    "    results[label] = {\n",
    "        'latencies': latencies,\n",
    "        'mean_ms': mean(latencies),\n",
    "        'median_ms': median(latencies),\n",
    "        'stdev_ms': stdev(latencies) if len(latencies) > 1 else 0.0,\n",
    "        'outputs': outputs,\n",
    "        'unique_outputs': len(set(outputs)),\n",
    "        'all_outputs': list(set(outputs)),\n",
    "    }\n",
    "\n",
    "# Save results under notebook folder in benchmarks/llm_throughput.json\n",
    "try:\n",
    "    nb_folder = Path(helper_path).parent if 'helper_path' in globals() else Path.cwd()\n",
    "except Exception:\n",
    "    nb_folder = Path.cwd()\n",
    "bench_dir = nb_folder / 'benchmarks'\n",
    "bench_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_file = bench_dir / 'llm_throughput.json'\n",
    "with open(out_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "console.print(f'[bold green]✅ Throughput/variability results saved to {out_file}[/bold green]')\n",
    "for label, stats in results.items():\n",
    "    console.print(f'[bold]{label}[/bold] outputs: {stats[\"outputs\"]}')\n",
    "    console.print(f'[bold]{label}[/bold] unique outputs: {stats[\"all_outputs\"]}')\n",
    "    console.print(f'[bold]{label}[/bold] unique count: {stats[\"unique_outputs\"]}')\n",
    "console.print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      LLM Throughput/Variability Benchmark                      </span>\n",
       "                                                                                \n",
       " <span style=\"font-weight: bold\"> Config              </span> <span style=\"font-weight: bold\"> Mean (ms) </span> <span style=\"font-weight: bold\"> Median (ms) </span> <span style=\"font-weight: bold\"> StdDev (ms) </span> <span style=\"font-weight: bold\"> Unique Outputs </span> \n",
       " ────────────────────────────────────────────────────────────────────────────── \n",
       " <span style=\"color: #008080; text-decoration-color: #008080\"> MockLLM (default)   </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.5       </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.4         </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 0.4         </span> <span style=\"color: #800080; text-decoration-color: #800080\"> 5              </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080\"> MockLLM (high temp) </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.1       </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.1         </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 0.1         </span> <span style=\"color: #800080; text-decoration-color: #800080\"> 5              </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080\"> Simulated live      </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 206.1     </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 205.3       </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 5.3         </span> <span style=\"color: #800080; text-decoration-color: #800080\"> 5              </span> \n",
       "                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      LLM Throughput/Variability Benchmark                      \u001b[0m\n",
       "                                                                                \n",
       " \u001b[1m \u001b[0m\u001b[1mConfig             \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mMean (ms)\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mMedian (ms)\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStdDev (ms)\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mUnique Outputs\u001b[0m\u001b[1m \u001b[0m \n",
       " ────────────────────────────────────────────────────────────────────────────── \n",
       " \u001b[36m \u001b[0m\u001b[36mMockLLM (default)  \u001b[0m\u001b[36m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.5      \u001b[0m\u001b[32m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.4        \u001b[0m\u001b[32m \u001b[0m \u001b[33m \u001b[0m\u001b[33m0.4        \u001b[0m\u001b[33m \u001b[0m \u001b[35m \u001b[0m\u001b[35m5             \u001b[0m\u001b[35m \u001b[0m \n",
       " \u001b[36m \u001b[0m\u001b[36mMockLLM (high temp)\u001b[0m\u001b[36m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.1      \u001b[0m\u001b[32m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.1        \u001b[0m\u001b[32m \u001b[0m \u001b[33m \u001b[0m\u001b[33m0.1        \u001b[0m\u001b[33m \u001b[0m \u001b[35m \u001b[0m\u001b[35m5             \u001b[0m\u001b[35m \u001b[0m \n",
       " \u001b[36m \u001b[0m\u001b[36mSimulated live     \u001b[0m\u001b[36m \u001b[0m \u001b[32m \u001b[0m\u001b[32m206.1    \u001b[0m\u001b[32m \u001b[0m \u001b[32m \u001b[0m\u001b[32m205.3      \u001b[0m\u001b[32m \u001b[0m \u001b[33m \u001b[0m\u001b[33m5.3        \u001b[0m\u001b[33m \u001b[0m \u001b[35m \u001b[0m\u001b[35m5             \u001b[0m\u001b[35m \u001b[0m \n",
       "                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 16.3 Present results in a concise table\n",
    "import json\n",
    "from pathlib import Path\n",
    "from rich.table import Table\n",
    "from rich import box\n",
    "\n",
    "try:\n",
    "    nb_folder = Path(helper_path).parent if 'helper_path' in globals() else Path.cwd()\n",
    "except Exception:\n",
    "    nb_folder = Path.cwd()\n",
    "bench_dir = nb_folder / 'benchmarks'\n",
    "in_file = bench_dir / 'llm_throughput.json'\n",
    "if in_file.exists():\n",
    "    data = json.loads(in_file.read_text(encoding='utf-8'))\n",
    "    table = Table(title=\"LLM Throughput/Variability Benchmark\", box=box.SIMPLE)\n",
    "    table.add_column(\"Config\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Mean (ms)\", style=\"green\")\n",
    "    table.add_column(\"Median (ms)\", style=\"green\")\n",
    "    table.add_column(\"StdDev (ms)\", style=\"yellow\")\n",
    "    table.add_column(\"Unique Outputs\", style=\"magenta\")\n",
    "    for label, stats in data.items():\n",
    "        table.add_row(\n",
    "            label,\n",
    "            f\"{stats['mean_ms']:.1f}\",\n",
    "            f\"{stats['median_ms']:.1f}\",\n",
    "            f\"{stats['stdev_ms']:.1f}\",\n",
    "            str(stats['unique_outputs'])\n",
    "        )\n",
    "    console.print(table)\n",
    "else:\n",
    "    console.print('[bold yellow]⚠️ No throughput/variability JSON found to display. Run the previous cell first.[/bold yellow]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      LLM Latency Benchmark                       </span>\n",
       "                                                                  \n",
       " <span style=\"font-weight: bold\"> Type           </span> <span style=\"font-weight: bold\"> Count </span> <span style=\"font-weight: bold\"> Mean (ms) </span> <span style=\"font-weight: bold\"> Median (ms) </span> <span style=\"font-weight: bold\"> StdDev (ms) </span> \n",
       " ──────────────────────────────────────────────────────────────── \n",
       " <span style=\"color: #008080; text-decoration-color: #008080\"> MockLLM        </span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 3     </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.8       </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.0         </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 1.3         </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080\"> Simulated Live </span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 3     </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 209.3     </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 212.0       </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 7.7         </span> \n",
       "                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      LLM Latency Benchmark                       \u001b[0m\n",
       "                                                                  \n",
       " \u001b[1m \u001b[0m\u001b[1mType          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mCount\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mMean (ms)\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mMedian (ms)\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStdDev (ms)\u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────────────────────────────── \n",
       " \u001b[36m \u001b[0m\u001b[36mMockLLM       \u001b[0m\u001b[36m \u001b[0m \u001b[37m \u001b[0m\u001b[37m3    \u001b[0m\u001b[37m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.8      \u001b[0m\u001b[32m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.0        \u001b[0m\u001b[32m \u001b[0m \u001b[33m \u001b[0m\u001b[33m1.3        \u001b[0m\u001b[33m \u001b[0m \n",
       " \u001b[36m \u001b[0m\u001b[36mSimulated Live\u001b[0m\u001b[36m \u001b[0m \u001b[37m \u001b[0m\u001b[37m3    \u001b[0m\u001b[37m \u001b[0m \u001b[32m \u001b[0m\u001b[32m209.3    \u001b[0m\u001b[32m \u001b[0m \u001b[32m \u001b[0m\u001b[32m212.0      \u001b[0m\u001b[32m \u001b[0m \u001b[33m \u001b[0m\u001b[33m7.7        \u001b[0m\u001b[33m \u001b[0m \n",
       "                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      LLM Throughput/Variability Benchmark                      </span>\n",
       "                                                                                \n",
       " <span style=\"font-weight: bold\"> Config              </span> <span style=\"font-weight: bold\"> Mean (ms) </span> <span style=\"font-weight: bold\"> Median (ms) </span> <span style=\"font-weight: bold\"> StdDev (ms) </span> <span style=\"font-weight: bold\"> Unique Outputs </span> \n",
       " ────────────────────────────────────────────────────────────────────────────── \n",
       " <span style=\"color: #008080; text-decoration-color: #008080\"> MockLLM (default)   </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.5       </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.4         </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 0.4         </span> <span style=\"color: #800080; text-decoration-color: #800080\"> 5              </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080\"> MockLLM (high temp) </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.1       </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 0.1         </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 0.1         </span> <span style=\"color: #800080; text-decoration-color: #800080\"> 5              </span> \n",
       " <span style=\"color: #008080; text-decoration-color: #008080\"> Simulated live      </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 206.1     </span> <span style=\"color: #008000; text-decoration-color: #008000\"> 205.3       </span> <span style=\"color: #808000; text-decoration-color: #808000\"> 5.3         </span> <span style=\"color: #800080; text-decoration-color: #800080\"> 5              </span> \n",
       "                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      LLM Throughput/Variability Benchmark                      \u001b[0m\n",
       "                                                                                \n",
       " \u001b[1m \u001b[0m\u001b[1mConfig             \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mMean (ms)\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mMedian (ms)\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStdDev (ms)\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mUnique Outputs\u001b[0m\u001b[1m \u001b[0m \n",
       " ────────────────────────────────────────────────────────────────────────────── \n",
       " \u001b[36m \u001b[0m\u001b[36mMockLLM (default)  \u001b[0m\u001b[36m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.5      \u001b[0m\u001b[32m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.4        \u001b[0m\u001b[32m \u001b[0m \u001b[33m \u001b[0m\u001b[33m0.4        \u001b[0m\u001b[33m \u001b[0m \u001b[35m \u001b[0m\u001b[35m5             \u001b[0m\u001b[35m \u001b[0m \n",
       " \u001b[36m \u001b[0m\u001b[36mMockLLM (high temp)\u001b[0m\u001b[36m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.1      \u001b[0m\u001b[32m \u001b[0m \u001b[32m \u001b[0m\u001b[32m0.1        \u001b[0m\u001b[32m \u001b[0m \u001b[33m \u001b[0m\u001b[33m0.1        \u001b[0m\u001b[33m \u001b[0m \u001b[35m \u001b[0m\u001b[35m5             \u001b[0m\u001b[35m \u001b[0m \n",
       " \u001b[36m \u001b[0m\u001b[36mSimulated live     \u001b[0m\u001b[36m \u001b[0m \u001b[32m \u001b[0m\u001b[32m206.1    \u001b[0m\u001b[32m \u001b[0m \u001b[32m \u001b[0m\u001b[32m205.3      \u001b[0m\u001b[32m \u001b[0m \u001b[33m \u001b[0m\u001b[33m5.3        \u001b[0m\u001b[33m \u001b[0m \u001b[35m \u001b[0m\u001b[35m5             \u001b[0m\u001b[35m \u001b[0m \n",
       "                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:47.332 | INFO     | research_agent_framework.logging:info:92 - Benchmarks displayed.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:47.332 | INFO     | research_agent_framework.logging:info:92 - Benchmarks displayed.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Benchmarks persisted in d:\\repos\\tpai_deep_research_from_scratch\\notebooks\\benchmarks</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✅ Benchmarks persisted in d:\\repos\\tpai_deep_research_from_scratch\\notebooks\\benchmarks\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 16.4 Benchmark summary and persistent logging\n",
    "import json\n",
    "from pathlib import Path\n",
    "from statistics import mean, median, stdev\n",
    "from rich.table import Table\n",
    "from rich import box\n",
    "\n",
    "try:\n",
    "    nb_folder = Path(helper_path).parent if 'helper_path' in globals() else Path.cwd()\n",
    "except Exception:\n",
    "    nb_folder = Path.cwd()\n",
    "bench_dir = nb_folder / 'benchmarks'\n",
    "lat_file = bench_dir / 'llm_latency.json'\n",
    "thr_file = bench_dir / 'llm_throughput.json'\n",
    "if not lat_file.exists() and not thr_file.exists():\n",
    "    console.print('[bold yellow]No benchmark results found. Run the benchmark cells first.[/bold yellow]')\n",
    "else:\n",
    "    # Latency summary\n",
    "    if lat_file.exists():\n",
    "        data = json.loads(lat_file.read_text(encoding='utf-8'))\n",
    "        def safe_stats(lst):\n",
    "            return { 'count': len(lst), 'mean_ms': mean(lst) if lst else None, 'median_ms': median(lst) if lst else None, 'stdev_ms': stdev(lst) if len(lst) > 1 else 0.0 }\n",
    "        mock_stats = safe_stats(data.get('mock', {}).get('runs', []) or [])\n",
    "        sim_stats = safe_stats(data.get('simulated_live', {}).get('runs', []) or [])\n",
    "        table = Table(title=\"LLM Latency Benchmark\", box=box.SIMPLE)\n",
    "        table.add_column(\"Type\", style=\"cyan\", no_wrap=True)\n",
    "        table.add_column(\"Count\", style=\"white\")\n",
    "        table.add_column(\"Mean (ms)\", style=\"green\")\n",
    "        table.add_column(\"Median (ms)\", style=\"green\")\n",
    "        table.add_column(\"StdDev (ms)\", style=\"yellow\")\n",
    "        table.add_row(\"MockLLM\", str(mock_stats['count']), f\"{mock_stats['mean_ms']:.1f}\", f\"{mock_stats['median_ms']:.1f}\", f\"{mock_stats['stdev_ms']:.1f}\")\n",
    "        table.add_row(\"Simulated Live\", str(sim_stats['count']), f\"{sim_stats['mean_ms']:.1f}\", f\"{sim_stats['median_ms']:.1f}\", f\"{sim_stats['stdev_ms']:.1f}\")\n",
    "        console.print(table)\n",
    "    # Throughput/variability summary\n",
    "    if thr_file.exists():\n",
    "        data = json.loads(thr_file.read_text(encoding='utf-8'))\n",
    "        table = Table(title=\"LLM Throughput/Variability Benchmark\", box=box.SIMPLE)\n",
    "        table.add_column(\"Config\", style=\"cyan\", no_wrap=True)\n",
    "        table.add_column(\"Mean (ms)\", style=\"green\")\n",
    "        table.add_column(\"Median (ms)\", style=\"green\")\n",
    "        table.add_column(\"StdDev (ms)\", style=\"yellow\")\n",
    "        table.add_column(\"Unique Outputs\", style=\"magenta\")\n",
    "        for label, stats in data.items():\n",
    "            table.add_row(\n",
    "                label,\n",
    "                f\"{stats['mean_ms']:.1f}\",\n",
    "                f\"{stats['median_ms']:.1f}\",\n",
    "                f\"{stats['stdev_ms']:.1f}\",\n",
    "                str(stats['unique_outputs'])\n",
    "            )\n",
    "        console.print(table)\n",
    "    # Persistent logs for CI and run logs\n",
    "    try:\n",
    "        logger.info('Benchmarks displayed.')\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Also write a small README with the report location\n",
    "    readme = bench_dir / 'README.txt'\n",
    "    readme.write_text(f'Benchmark artifacts in: {bench_dir}\\n', encoding='utf-8')\n",
    "    console.print(f'[bold green]✅ Benchmarks persisted in {bench_dir}[/bold green]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.1 Common Setup Issues and Resolutions\n",
    " \n",
    "This section documents frequent setup issues encountered in this research framework and notebook, with troubleshooting steps and logging tips for each.\n",
    " \n",
    "### 17.1.1 Environment not loading (.env missing, wrong path)\n",
    "- **Symptom:** Settings do not reflect expected environment variables; adapters default to mock.\n",
    "- **Resolution:** Ensure `.env` exists in repo root or set variables in your shell. Use `get_settings(force_reload=True)` to reload.\n",
    "- **Logging:** `logger.info('Reloaded settings from environment.')`\n",
    " \n",
    "### 17.1.2 Import errors (src not on PYTHONPATH/sys.path)\n",
    "- **Symptom:** `ModuleNotFoundError` for project modules.\n",
    "- **Resolution:** Use notebook bootstrap helper to add `src` to `sys.path`. Restart kernel if needed.\n",
    "- **Logging:** `logger.error('Import error: src not found on sys.path.')`\n",
    " \n",
    "### 17.1.3 Logging not stylized (Rich/Loguru misconfigured)\n",
    "- **Symptom:** Logs lack color/bold/formatting in notebook output.\n",
    "- **Resolution:** Ensure Rich Console is used; see Section 15.4 for stylized logging tips.\n",
    "- **Logging:** `logger.info('Rich logging enabled.')`\n",
    " \n",
    "### 17.1.4 Adapter keys missing (SERPAPI/TAVILY)\n",
    "- **Symptom:** Search adapters always use mock mode.\n",
    "- **Resolution:** Set `SERPAPI_API_KEY` or `TAVILY_API_KEY` in environment. Check with `os.environ.get()` in notebook.\n",
    "- **Logging:** `logger.warning('Adapter API key missing; using mock adapter.')`\n",
    " \n",
    "### 17.1.5 Notebook kernel issues (restart, re-import)\n",
    "- **Symptom:** Imports or settings do not update after code changes.\n",
    "- **Resolution:** Restart kernel and re-run bootstrap cells. Use `force_reload=True` for settings.\n",
    "- **Logging:** `logger.info('Kernel restarted; settings reloaded.')`\n",
    " \n",
    "### 17.1.6 Add logging to each troubleshooting step\n",
    "- **Tip:** Use `logger.info()`, `logger.warning()`, and `logger.error()` at each step for clarity and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.2 Prompt/LLM Pitfalls and Mitigations\n",
    " \n",
    "This section documents common issues with prompts and LLM configuration, and provides mitigation strategies with logging for each.\n",
    " \n",
    "### 17.2.1 Prompt ambiguity (unclear instructions)\n",
    "- **Symptom:** LLM output is off-topic, vague, or irrelevant.\n",
    "- **Mitigation:** Refine prompt wording for clarity and specificity. Use examples and constraints.\n",
    "- **Logging:** `logger.warning('Prompt ambiguity detected; refining prompt.')`\n",
    " \n",
    "### 17.2.2 Overly high/low temperature settings\n",
    "- **Symptom:** Output is too random (high temp) or repetitive (low temp).\n",
    "- **Mitigation:** Set temperature to match desired creativity. Use 0.0 for deterministic, 0.7+ for creative.\n",
    "- **Logging:** `logger.info(f'Temperature set to {settings.model_temperature}')`\n",
    " \n",
    "### 17.2.3 Max tokens too low (truncated output)\n",
    "- **Symptom:** LLM output is cut off or incomplete.\n",
    "- **Mitigation:** Increase `max_tokens` to allow longer responses. Validate output length.\n",
    "- **Logging:** `logger.warning('Output truncated; consider increasing max_tokens.')`\n",
    " \n",
    "### 17.2.4 Provider/model mismatch\n",
    "- **Symptom:** LLM fails or returns errors due to unsupported model/provider.\n",
    "- **Mitigation:** Check `MODEL_NAME` and provider compatibility. Use mock for unsupported models.\n",
    "- **Logging:** `logger.error('Provider/model mismatch; using mock LLM.')`\n",
    " \n",
    "### 17.2.5 Logging prompt, config, and output for debugging\n",
    "- **Tip:** Always log prompt, config, and output for reproducibility and debugging.\n",
    "- **Logging:** `logger.info(f'Prompt: {prompt}\\nConfig: {config}\\nOutput: {output}')`\n",
    " \n",
    "### 17.2.6 Add mitigation strategies and logging for each\n",
    "- **Tip:** Document mitigation steps and add logging at each decision point for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.3 Links to Deeper References\n",
    " \n",
    "This section provides links to documentation and best practices for further learning and troubleshooting.\n",
    " \n",
    "- [LangChain Documentation](https://docs.langchain.com/docs/langsmith)\n",
    "- [Pydantic Settings Docs](https://docs.pydantic.dev/latest/concepts/settings/)\n",
    "- [Rich Logging Documentation](https://rich.readthedocs.io/en/stable/logging.html)\n",
    "- [Loguru Logging Documentation](https://loguru.readthedocs.io/en/stable/)\n",
    "- [Pytest Best Practices](https://docs.pytest.org/en/stable/how-to/best-practices.html)\n",
    " \n",
    "**Tip:** Log links and references in your code and notebook for easy access during debugging and development.\n",
    "- **Logging:** `logger.info('See LangChain docs for tracing setup.')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:47.345 | INFO     | research_agent_framework.logging:info:92 - Adding 2 + 3</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:47.345 | INFO     | research_agent_framework.logging:info:92 - Adding 2 + 3\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">2025-09-13 17:32:47.347 | INFO     | research_agent_framework.logging:info:92 - Result of add(2, 3): 5</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m2025-09-13 17:32:47.347 | INFO     | research_agent_framework.logging:info:92 - Result of add(2, 3): 5\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">add(</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">) = </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> (TDD assertion passed)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32madd\u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m2\u001b[0m\u001b[1;32m, \u001b[0m\u001b[1;32m3\u001b[0m\u001b[1;32m)\u001b[0m\u001b[1;32m = \u001b[0m\u001b[1;32m5\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mTDD assertion passed\u001b[0m\u001b[1;32m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 18.2 Minimal code to pass TDD assertions (TDD mini-example)\n",
    "from assertpy import assert_that\n",
    "from research_agent_framework.config import get_logger, get_console\n",
    "\n",
    "logger = get_logger()\n",
    "console = get_console()\n",
    "\n",
    "def add(a, b):\n",
    "    logger.info(f\"Adding {a} + {b}\")\n",
    "    return a + b\n",
    "\n",
    "def test_add():\n",
    "    result = add(2, 3)\n",
    "    logger.info(f\"Result of add(2, 3): {result}\")\n",
    "    assert_that(result).is_equal_to(5)\n",
    "    console.print(f\"[bold green]add(2, 3) = {result} (TDD assertion passed)[/bold green]\")\n",
    "\n",
    "test_add()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.3 Test-Driven Loop: Red-Green-Refactor in Notebook\n",
    "\n",
    "This section demonstrates the TDD cycle directly in the notebook, with logging and commentary at each step. The process mirrors the repo's test-driven approach and keeps all four artifacts in sync.\n",
    "\n",
    "**Steps:**\n",
    "1. Write a failing test (assertion)\n",
    "2. Add minimal code to pass the test\n",
    "3. Refactor and improve with logging\n",
    "4. Repeat for new features\n",
    "\n",
    "All actions are logged and visible in both notebook and code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
